{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import requests\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de téléchargement des données depuis S3 ou une URL avec barre de progression\n",
    "def download_data(local_path, url=None, s3_path=None, bucket=None, endpoint=None):\n",
    "    \"\"\"\n",
    "    Télécharge un fichier depuis S3 ou une URL et le sauvegarde localement.\n",
    "    \"\"\"\n",
    "    # Créer le dossier si nécessaire\n",
    "    dir_path = os.path.dirname(local_path)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    \n",
    "    # Vérifier si le fichier existe déjà\n",
    "    if os.path.exists(local_path):\n",
    "        print(f\"Les données sont déjà téléchargées : {local_path}\")\n",
    "        return\n",
    "\n",
    "    # Télécharger depuis S3\n",
    "    if s3_path and bucket and endpoint:\n",
    "        print(\"Téléchargement depuis le bucket S3...\")\n",
    "        try:\n",
    "            s3 = boto3.client('s3', endpoint_url=endpoint)\n",
    "            s3.download_file(bucket, s3_path, local_path)\n",
    "            print(f\"Téléchargement effectué avec succès depuis S3 : {local_path}\")\n",
    "        except NoCredentialsError as e:\n",
    "            print(f\"Erreur d'authentification S3 : {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du téléchargement depuis S3 : {e}\")\n",
    "            return\n",
    "\n",
    "    # Télécharger depuis une URL\n",
    "    elif url:\n",
    "        print(\"Téléchargement depuis l'URL...\")\n",
    "        try:\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Barre de progression\n",
    "            total_size = int(response.headers.get('content-length', 0))\n",
    "            with open(local_path, 'wb') as f, tqdm(\n",
    "                desc=f\"Téléchargement {os.path.basename(local_path)}\",\n",
    "                total=total_size,\n",
    "                unit='B',\n",
    "                unit_scale=True,\n",
    "                unit_divisor=1024,\n",
    "            ) as bar:\n",
    "                for data in response.iter_content(chunk_size=1024):\n",
    "                    f.write(data)\n",
    "                    bar.update(len(data))\n",
    "            print(f\"Téléchargement effectué avec succès : {local_path}\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Erreur lors du téléchargement depuis l'URL : {e}\")\n",
    "            return\n",
    "\n",
    "    else:\n",
    "        print(\"Ni URL, ni chemin S3 spécifié. Impossible de télécharger les données.\")\n",
    "        return\n",
    "\n",
    "# Fonction pour lire les fichiers Parquet\n",
    "def read_parquet_data(local_path):\n",
    "    if os.path.exists(local_path):\n",
    "        try:\n",
    "            data = pq.read_table(local_path).to_pandas()\n",
    "            print(f\"Données Parquet chargées avec succès depuis : {local_path}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la lecture du fichier Parquet : {e}\")\n",
    "    else:\n",
    "        print(f\"Le fichier n'existe pas : {local_path}\")\n",
    "    return None\n",
    "\n",
    "# Fonction pour lire les fichiers CSV\n",
    "def read_csv_data(local_path):\n",
    "    if os.path.exists(local_path):\n",
    "        try:\n",
    "            data = pd.read_csv(local_path, sep=';')\n",
    "            print(f\"Données CSV chargées avec succès depuis : {local_path}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la lecture du fichier CSV : {e}\")\n",
    "    else:\n",
    "        print(f\"Le fichier n'existe pas : {local_path}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le répertoire courant\n",
    "os.chdir('/home/onyxia/work/methodes_ensemblistes_notebooks')\n",
    "\n",
    "# Vérification\n",
    "print(\"Nouveau répertoire courant :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement des fichiers en local\n",
    "\n",
    "# Depuis une URL\n",
    "download_data(\n",
    "    local_path=\"data/data_census_individuals.parquet\",\n",
    "    url=\"https://www.data.gouv.fr/fr/datasets/r/c8e1b241-75fe-43e9-a266-830fc30ec61d\"\n",
    ")\n",
    "download_data(\n",
    "    local_path=\"data/data_census_dwellings.parquet\",\n",
    "    url=\"https://www.data.gouv.fr/fr/datasets/r/f314175a-6d33-4ee4-b5eb-2cb6c29df2c2\"\n",
    ")\n",
    "download_data(\n",
    "    local_path=\"documentation/doc_census_individuals.csv\",\n",
    "    url=\"https://www.data.gouv.fr/fr/datasets/r/1c6c6ab2-b766-41a4-90f0-043173d5e9d1\"\n",
    ")\n",
    "download_data(\n",
    "    local_path=\"documentation/doc_census_dwellings.csv\",\n",
    "    url=\"https://www.data.gouv.fr/fr/datasets/r/c274705f-98db-4d9b-9674-578e04f03198\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des fichiers Parquet\n",
    "data_census_individuals = read_parquet_data(\"data/data_census_individuals.parquet\")\n",
    "data_census_dwellings = read_parquet_data(\"data/data_census_dwellings.parquet\")\n",
    "\n",
    "# Lecture des fichiers CSV\n",
    "doc_census_individuals = read_csv_data(\"documentation/doc_census_individuals.csv\")\n",
    "doc_census_dwellings = read_csv_data(\"documentation/doc_census_dwellings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un aperçu des données\n",
    "print(data_census_individuals.head())\n",
    "print(data_census_dwellings.head())\n",
    "print(doc_census_individuals.head())\n",
    "print(doc_census_dwellings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_census_individuals = read_csv_data(\"documentation/doc_census_individuals.csv\")\n",
    "print(\"doc_census_individuals\" in globals()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
