{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Premier exemple de classification binaire: prédire la détention du baccalauréat dans le recensement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le répertoire courant\n",
    "os.chdir('/home/onyxia/work/methodes_ensemblistes_notebooks')\n",
    "\n",
    "# Vérification\n",
    "print(\"Nouveau répertoire courant :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour lire les fichiers Parquet\n",
    "def read_parquet_data(local_path, var_name, force_reload=False):\n",
    "    \"\"\"\n",
    "    Charge un fichier Parquet, avec possibilité de forcer le rechargement même si la variable est en mémoire.\n",
    "    \n",
    "    Args:\n",
    "        local_path (str): Chemin du fichier Parquet.\n",
    "        var_name (str): Nom de la variable à vérifier dans l'espace de noms global.\n",
    "        force_reload (bool): Forcer le rechargement des données même si elles sont déjà en mémoire.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Données chargées depuis le fichier Parquet.\n",
    "    \"\"\"\n",
    "    if var_name in globals() and not force_reload:\n",
    "        print(f\"Les données '{var_name}' sont déjà en mémoire. Utilisez force_reload=True pour les recharger.\")\n",
    "        return globals()[var_name]\n",
    "    \n",
    "    if os.path.exists(local_path):\n",
    "        try:\n",
    "            data = pq.read_table(local_path).to_pandas()\n",
    "            print(f\"Données Parquet chargées avec succès depuis : {local_path}\")\n",
    "            globals()[var_name] = data  # Stocker la variable dans l'espace global\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la lecture du fichier Parquet : {e}\")\n",
    "    else:\n",
    "        print(f\"Le fichier n'existe pas : {local_path}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# Fonction pour lire les fichiers CSV\n",
    "def read_csv_data(local_path, var_name, force_reload=False):\n",
    "    \"\"\"\n",
    "    Charge un fichier CSV, avec possibilité de forcer le rechargement même si la variable est en mémoire.\n",
    "    \n",
    "    Args:\n",
    "        local_path (str): Chemin du fichier CSV.\n",
    "        var_name (str): Nom de la variable à vérifier dans l'espace de noms global.\n",
    "        force_reload (bool): Forcer le rechargement des données même si elles sont déjà en mémoire.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Données chargées depuis le fichier CSV.\n",
    "    \"\"\"\n",
    "    if var_name in globals() and not force_reload:\n",
    "        print(f\"Les données '{var_name}' sont déjà en mémoire. Utilisez force_reload=True pour les recharger.\")\n",
    "        return globals()[var_name]\n",
    "    \n",
    "    if os.path.exists(local_path):\n",
    "        try:\n",
    "            data = pd.read_csv(local_path, sep=';')\n",
    "            print(f\"Données CSV chargées avec succès depuis : {local_path}\")\n",
    "            globals()[var_name] = data  # Stocker la variable dans l'espace global\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la lecture du fichier CSV : {e}\")\n",
    "    else:\n",
    "        print(f\"Le fichier n'existe pas : {local_path}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données si elles ne sont pas déjà en mémoire\n",
    "data_census_individuals = read_parquet_data(\"data/data_census_individuals.parquet\", \"data_census_individuals\", force_reload=True)\n",
    "\n",
    "# Charger la documentation\n",
    "doc_census_individuals = read_csv_data(\"documentation/doc_census_individuals.csv\", \"doc_census_individuals\", force_reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Échantillonner les données (1/200)\n",
    "data_sample = data_census_individuals.sample(frac=1/200, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des variables liées à l'âge (autres que AGED) et des variables non pertinentes ou avec trop de modalités (pour commencer)\n",
    "columns_to_drop = [\n",
    "    'AGER20', 'AGEREV', 'AGEREVQ', 'ANAI', 'TRIRIS', 'IRIS', 'DNAI',\n",
    "    'DEPT', 'ARM', 'CANTVILLE', 'NUMMI', 'IPONDI'\n",
    "]\n",
    "data_clean = data_sample.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir la répartition des classes de diplôme\n",
    "print(data_clean['DIPL'].isna().sum())  # Vérification des valeurs manquantes\n",
    "print(data_clean['DIPL'].value_counts())  # Distribution des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une indicatrice de niveau baccalauréat\n",
    "\n",
    "# Préciser l'odre des catégories de DIPL (ZZ suivi des valeurs numériques croissantes)\n",
    "categories = ['ZZ'] + [f\"{i:02}\" for i in range(1, 20)]\n",
    "data_clean['DIPL'] = pd.Categorical(data_clean['DIPL'], categories=categories, ordered=True)\n",
    "\n",
    "# Créer la variable binaire 'bac'\n",
    "data_clean['bac'] = (data_clean['DIPL'] > '13').astype(int)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(data_clean[['DIPL', 'bac']].head(20))\n",
    "print(data_clean['bac'].value_counts())  # Distribution des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer la colonne 'DIPL' du DataFrame\n",
    "data_clean = data_clean.drop(columns=['DIPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les données en features (X) et la variable cible (y : DIPL)\n",
    "X = data_clean.drop(columns=['bac'])\n",
    "y = data_clean['bac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage \"one-hot\" des variables catégorielles\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Identifier les variables catégorielles\n",
    "categorical_cols = X.select_dtypes(include=['category']).columns\n",
    "\n",
    "# Appliquer le One-Hot Encoding sur les variables catégorielles\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Convertir les colonnes encodées en DataFrame avec les noms des catégories\n",
    "X_encoded = pd.DataFrame(\n",
    "    X_encoded, \n",
    "    index=X.index, \n",
    "    columns=encoder.get_feature_names_out(categorical_cols)\n",
    ")\n",
    "\n",
    "# Sélectionner les colonnes numériques\n",
    "numeric_cols = X.select_dtypes(exclude=['category'])\n",
    "\n",
    "# Concaténer les colonnes numériques et encodées uniquement si les colonnes numériques ne sont pas vides\n",
    "if not numeric_cols.empty:\n",
    "    X = pd.concat([numeric_cols, X_encoded], axis=1)\n",
    "else:\n",
    "    X = X_encoded\n",
    "\n",
    "# Vérification finale\n",
    "print(f\"Dimensions finales après encodage : X={X.shape}\")\n",
    "print(\"Aperçu de X :\")\n",
    "print(X.head())\n",
    "\n",
    "# Vérifier les dimensions après division\n",
    "print(f\"Dimensions après division : X={X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions avant et après l'encodage\n",
    "print(f\"Dimensions avant encodage : {X.shape[0]} lignes, {categorical_cols.shape[0]} variables catégorielles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Une première random forest avec des hyperparamètres \"standards\" (non optimisés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle Random Forest pour classification\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=100,\n",
    "    random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Temps d'exécution du modèle Random Forest : {elapsed_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance avec une matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=rf_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=rf_model.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion pour la prédiction du niveau de diplôme\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Nombre d'arbres: n_estimators\n",
    "\n",
    "L'augmentation du nombre d'arbres améliore la stabilité et la précision des estimations. Toutefois, un nombre d'arbre élevé peut considérablement allongés le temps de calcul. \n",
    "\n",
    "L'objectif est de trouver un compromis entre stabilité et temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_estimators_range = [10, 50, 100, 200, 500, 1000]\n",
    "scores = []\n",
    "\n",
    "for n in n_estimators_range:\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=n, max_features='sqrt', min_samples_leaf=100, random_state=123\n",
    "    )\n",
    "    score = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "plt.plot(n_estimators_range, scores, marker='o')\n",
    "plt.xlabel('Nombre d\\'arbres (n_estimators)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Influence de n_estimators')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Nombre de caractéristiques utilisées pour chaque split : max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Différentes valeurs de max_features à tester\n",
    "max_features_range = ['sqrt', 'log2', None, 0.1, 0.3, 0.5]\n",
    "scores = []\n",
    "\n",
    "for max_features in max_features_range:\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=500,  # Fixé à 500 arbres\n",
    "        max_features=max_features,\n",
    "        min_samples_leaf=100,\n",
    "        random_state=123\n",
    "    )\n",
    "    score = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "# Convertir les noms des catégories en chaînes lisibles (pour l'affichage)\n",
    "max_features_labels = [str(val) if val else 'All' for val in max_features_range]\n",
    "\n",
    "# Tracer les résultats\n",
    "plt.plot(max_features_labels, scores, marker='o')\n",
    "plt.xlabel('Valeurs de max_features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Influence de max_features')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Taille minimale des feuilles : min_samples_leaf\n",
    "\n",
    "Pour de faibles valeurs du nombre minimum d'observations par feuille (noeud terminal), le modèle risque de sur-ajuster les données d'entraînement; pour des valeurs élevées, le modèle devient plus simple, ce qui peut entraîner un sous-ajustement.\n",
    "\n",
    "L'objectif est donc de trouver un compromis optimal entre ces deux situations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Différentes valeurs de min_samples_leaf à tester\n",
    "min_samples_leaf_range = [1, 5, 10, 50, 100, 500]\n",
    "scores = []\n",
    "\n",
    "for min_samples_leaf in min_samples_leaf_range:\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=500,  # Fixé à 500 arbres\n",
    "        max_features='sqrt',\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=123\n",
    "    )\n",
    "    score = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "# Tracer les résultats\n",
    "plt.plot(min_samples_leaf_range, scores, marker='o')\n",
    "plt.xlabel('Valeurs de min_samples_leaf')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Influence de min_samples_leaf')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Grid Search pour optimiser plusieurs hyperparamètres à la fois\n",
    "\n",
    "GridSearchCV de scikit-learn permet d'optimiser de manière simultanée plusieurs hyperparamètres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_leaf': [1, 10, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=123),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "print(\"Meilleure précision :\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Evaluer la performance du modèle optimisé par Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Précision sur le jeu de test :\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance avec une matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=rf_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=rf_model.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion pour la prédiction du niveau de diplôme\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## Importance des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des variables (Mean Decrease in Impurity)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rassembler l'importance des modalités d'une même variable\n",
    "def calculate_aggregated_importance(X, feature_importances):\n",
    "    \"\"\"\n",
    "    Agrège l'importance des variables catégorielles encodées en colonnes multiples.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Les données d'entraînement (features).\n",
    "        feature_importances (array): Les importances des variables calculées par le modèle.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Importance des variables agrégées par nom de variable.\n",
    "    \"\"\"\n",
    "    # Récupérer les noms des colonnes\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Initialiser un dictionnaire pour stocker les importances agrégées\n",
    "    aggregated_importance = {}\n",
    "\n",
    "    for col in feature_names:\n",
    "        # Identifier les variables spécifiques pour regrouper correctement\n",
    "        if col.startswith('STAT_CONJ_'):\n",
    "            variable = 'STAT_CONJ'\n",
    "        elif col.startswith('STATR_'):\n",
    "            variable = 'STATR'\n",
    "        else:\n",
    "            # Utiliser le préfixe par défaut basé sur le premier segment avant \"_\"\n",
    "            variable = col.split('_')[0]\n",
    "        \n",
    "        # Additionner les importances pour chaque variable \"parent\"\n",
    "        if variable in aggregated_importance:\n",
    "            aggregated_importance[variable] += feature_importances[feature_names.get_loc(col)]\n",
    "        else:\n",
    "            aggregated_importance[variable] = feature_importances[feature_names.get_loc(col)]\n",
    "\n",
    "    # Convertir en DataFrame trié par importance\n",
    "    aggregated_df = pd.DataFrame({\n",
    "        'Variable': aggregated_importance.keys(),\n",
    "        'Importance': aggregated_importance.values()\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appeler la fonction pour regrouper les importances\n",
    "aggregated_importance_df = calculate_aggregated_importance(X, rf_model.feature_importances_)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(aggregated_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les libellés des variables depuis le dictionnaire\n",
    "doc_census_individuals_noms_variables = doc_census_individuals[['COD_VAR', 'LIB_VAR']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associer les libellés (descriptions) aux variables d'importance\n",
    "importance_df_with_labels = aggregated_importance_df.merge(\n",
    "    doc_census_individuals_noms_variables,\n",
    "    left_on='Variable',\n",
    "    right_on='COD_VAR',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour visualiser des n variables les plus importantes\n",
    "def plot_top_n_variables(importance_df, variable_col='Variable', importance_col='Importance', top_n=10):\n",
    "    \"\"\"\n",
    "    Visualise les n variables les plus importantes à partir d'un DataFrame d'importance.\n",
    "\n",
    "    Parameters:\n",
    "    - importance_df (pd.DataFrame): Un DataFrame contenant les colonnes spécifiées.\n",
    "    - variable_col (str): Le nom de la colonne contenant les noms des variables.\n",
    "    - importance_col (str): Le nom de la colonne contenant les valeurs d'importance.\n",
    "    - top_n (int): Le nombre de variables les plus importantes à afficher.\n",
    "    \"\"\"\n",
    "    # Vérifier si les colonnes existent\n",
    "    if variable_col not in importance_df.columns or importance_col not in importance_df.columns:\n",
    "        raise ValueError(f\"Les colonnes '{variable_col}' et/ou '{importance_col}' ne sont pas présentes dans le DataFrame.\")\n",
    "\n",
    "    # Trier par importance décroissante\n",
    "    top_variables = importance_df.sort_values(by=importance_col, ascending=False).head(top_n)\n",
    "\n",
    "    # Création du graphique\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(top_variables[variable_col], top_variables[importance_col], color='steelblue')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Variable\")\n",
    "    plt.title(f\"Top {top_n} variables les plus importantes\")\n",
    "    plt.gca().invert_yaxis()  # Afficher les plus importantes en haut\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des variables les plus importantes\n",
    "plot_top_n_variables(\n",
    "    importance_df = importance_df_with_labels,\n",
    "    variable_col='LIB_VAR',\n",
    "    importance_col='Importance',\n",
    "    top_n=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
