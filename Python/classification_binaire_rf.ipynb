{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Premier exemple de classification binaire: prédire la détention du baccalauréat dans le recensement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Présentation\n",
    "Dans ce tutoriel, nous allons voir comment utiliser une forêt aléatoire pour prédire si un individu a obtenu le baccalauréat à partir de données du recensement de la population (Insee). Nous présentons les étapes de préparation des données, d'entraînement du modèle, d'optimisation des hyperparamètres et d'interprétation des résultats.\n",
    "\n",
    "Le jeu de données contient des informations individuelles issues du recensement, telles que l'âge, le niveau d'éducation, la situation professionnelle, etc.\n",
    "\n",
    "L'objectif ici est de prédire si un individu a obtenu le baccalauréat en fonction des autres caractéristiques observées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques pour la manipulation des données\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bibliothèques pour la visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliothèques pour le traitement des données\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Bibliothèques pour le modèle et l'évaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Pour mesurer le temps d'exécution\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Configuration du répertoire de travail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le répertoire du projet \n",
    "os.chdir('/home/onyxia/work/methodes_ensemblistes_notebooks')\n",
    "\n",
    "# Vérification\n",
    "current_dir = os.getcwd()\n",
    "print(\"Répertoire de travail :\", current_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Chargement et aperçu des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour lire les fichiers Parquet\n",
    "def read_parquet_data(local_path):\n",
    "    if os.path.exists(local_path):\n",
    "        try:\n",
    "            data = pq.read_table(local_path).to_pandas()\n",
    "            print(f\"Données Parquet chargées avec succès depuis : {local_path}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la lecture du fichier Parquet : {e}\")\n",
    "    else:\n",
    "        print(f\"Le fichier n'existe pas : {local_path}\")\n",
    "    return None\n",
    "\n",
    "# Fonction pour lire les fichiers CSV\n",
    "def read_csv_data(local_path):\n",
    "    if os.path.exists(local_path):\n",
    "        try:\n",
    "            data = pd.read_csv(local_path, sep=';')\n",
    "            print(f\"Données CSV chargées avec succès depuis : {local_path}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la lecture du fichier CSV : {e}\")\n",
    "    else:\n",
    "        print(f\"Le fichier n'existe pas : {local_path}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données si elles ne sont pas déjà en mémoire\n",
    "data_census_individuals = read_parquet_data(\"data/data_census_individuals.parquet\", \"data_census_individuals\", force_reload=True)\n",
    "\n",
    "# Charger la documentation\n",
    "doc_census_individuals = read_csv_data(\"documentation/doc_census_individuals.csv\", \"doc_census_individuals\", force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les premières lignes du jeu de données\n",
    "data_census_individuals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Echantillonnage des données\n",
    "Compte tenu de l'objectif purement pédagogique de ce tutoriel, nous tirons un échantillon aléatoire (0,5 %), représentatif de l'ensemble des données initiales, afin d'accélérer les calculs dans les sections suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Échantillonner les données (1/200)\n",
    "data_sample = data_census_individuals.sample(frac=1/200, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Suppression de variables redondantes ou contenant trop de modalités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des variables liées à l'âge (autres que AGED) et des variables non pertinentes ou avec trop de modalités (pour commencer)\n",
    "columns_to_drop = [\n",
    "    'AGER20', 'AGEREV', 'AGEREVQ', 'ANAI', 'TRIRIS', 'IRIS', 'DNAI',\n",
    "    'DEPT', 'ARM', 'CANTVILLE', 'NUMMI', 'IPONDI'\n",
    "]\n",
    "data_clean = data_sample.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir la répartition des classes de diplôme\n",
    "print(data_clean['DIPL'].isna().sum())  # Vérification des valeurs manquantes\n",
    "print(data_clean['DIPL'].value_counts())  # Distribution des classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Création de la variable cible : une indicatrice qui vaut 1 pour les détenteurs du baccalauréat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préciser l'odre des catégories de DIPL (ZZ suivi des valeurs numériques croissantes)\n",
    "categories = ['ZZ'] + [f\"{i:02}\" for i in range(1, 20)]\n",
    "data_clean['DIPL'] = pd.Categorical(data_clean['DIPL'], categories=categories, ordered=True)\n",
    "\n",
    "# Créer la variable binaire 'bac'\n",
    "data_clean['bac'] = (data_clean['DIPL'] > '13').astype(int)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(data_clean[['DIPL', 'bac']].head(20))\n",
    "print(data_clean['bac'].value_counts())  # Distribution des classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Préparation des variables explicatives (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer la colonne 'DIPL' du DataFrame (prédicteur parfait du baccalauréat)\n",
    "data_clean = data_clean.drop(columns=['DIPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les données en features (X) et la variable cible (y : bac)\n",
    "X = data_clean.drop(columns=['bac'])\n",
    "y = data_clean['bac']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Identification des variables catégorielles et numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier les variables catégorielles\n",
    "categorical_cols = X.select_dtypes(include=['category']).columns\n",
    "\n",
    "# Identifier les colonnes numériques\n",
    "numeric_cols = X.select_dtypes(exclude=['category'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Encodage des variables catégorielles\n",
    "Les variables catégorielles sont transformées en variables numériques grâce au One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage \"one-hot\" des variables catégorielles\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Appliquer le One-Hot Encoding sur les variables catégorielles\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Convertir les colonnes encodées en DataFrame avec les noms des catégories\n",
    "X_encoded = pd.DataFrame(\n",
    "    X_encoded, \n",
    "    index=X.index, \n",
    "    columns=encoder.get_feature_names_out(categorical_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Rassembler les variables numériques et catégorielles encodées dans une même table\n",
    "Nous réunissons toutes les variables explicatives (catégorielles encodées et numériques) dans X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concaténer les colonnes numériques et encodées (uniquement si les colonnes numériques ne sont pas vides)\n",
    "if not numeric_cols.empty:\n",
    "    X = pd.concat([numeric_cols, X_encoded], axis=1)\n",
    "else:\n",
    "    X = X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les dimensions finales\n",
    "print(f\"Dimensions de X : {X.shape}\")\n",
    "print(f\"Nombre de variables numériques : {len(numeric_cols)}\")\n",
    "print(f\"Nombre de variables catégorielles encodées : {X_encoded.shape[1]}\")\n",
    "\n",
    "# Dimensions avant et après l'encodage\n",
    "print(f\"Dimensions avant encodage : {X.shape[0]} lignes, {categorical_cols.shape[0]} variables catégorielles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Division des données en ensemble d'entraînement et de test\n",
    "La stratification assure que la proportion des classes est la même dans les ensembles d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement (80%) et de test (20%) avec stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# Une première random forest avec des hyperparamètres \"standards\" (non optimisés)\n",
    "- n_estimators : Nombre d'arbres dans la forêt.\n",
    "- max_features : Nombre de variables à considérer pour déterminer le meilleur split.\n",
    "- min_samples_leaf : Nombre minimum d'échantillons dans une feuille terminale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un modèle Random Forest pour une classification avec des hyperparamètres de base\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=100,\n",
    "    random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Temps d'exécution du modèle Random Forest : {elapsed_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## Evaluation sur le jeu de test\n",
    "\n",
    "La matrice de confusion permet de visualiser les erreurs de classification.\n",
    "Le rapport de classification donne des métriques importantes comme la précision, le rappel et le F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance avec une matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=rf_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=rf_model.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion pour la prédiction du niveau de diplôme\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "# Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Influence du nombre d'arbres (n_estimators)\n",
    "\n",
    "L'augmentation du nombre d'arbres améliore la stabilité et la précision des estimations. Toutefois, un nombre d'arbre élevé peut considérablement allongés le temps de calcul. \n",
    "\n",
    "L'objectif est de trouver un compromis entre stabilité et temps de calcul.\n",
    "\n",
    "Méthode: On observe comment l'accuracy évolue avec le nombre d'arbres.\n",
    "Cela permet de déterminer si l'augmentation du nombre d'arbres améliore significativement la performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_range = [10, 50, 100, 200, 500, 1000]\n",
    "scores = []\n",
    "\n",
    "for n in n_estimators_range:\n",
    "    \n",
    "    print(f\"Entraînement en cours avec n_estimators = {n}\")  # Affichage de la valeur actuelle\n",
    "\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=n, \n",
    "        max_features='sqrt', \n",
    "        min_samples_leaf=100, \n",
    "        random_state=123,\n",
    "        n_jobs=-1  # Parallélise la construction des arbres\n",
    "    )\n",
    "    score = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "plt.plot(n_estimators_range, scores, marker='o')\n",
    "plt.xlabel('Nombre d\\'arbres (n_estimators)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Influence de n_estimators')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## Influence du nombre de caractéristiques (max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_options = ['sqrt', 0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.8, None]\n",
    "scores = []\n",
    "d = X_train.shape[1]  # Nombre total de caractéristiques dans le jeu de données\n",
    "\n",
    "# Stocker les résultats pour le tri lors de la visualisation\n",
    "results = []\n",
    "\n",
    "for mf in max_features_options:\n",
    "\n",
    "    print(f\"Entraînement en cours avec max_features = {mf} ({num_features} features)\")  # Affichage de la valeur actuelle\n",
    "\n",
    "    # Calculer le nombre de features sélectionnés pour chaque option\n",
    "    if isinstance(mf, float):  # Si mf est une fraction\n",
    "        num_features = int(mf * d)\n",
    "    elif mf == 'sqrt':  # Si mf est 'sqrt'\n",
    "        num_features = int(np.sqrt(d))\n",
    "    elif mf == 'log2':  # Si mf est 'log2'\n",
    "        num_features = int(np.log2(d))\n",
    "    elif mf is None:  # Si mf est None\n",
    "        num_features = d\n",
    "    else:\n",
    "        num_features = None\n",
    "\n",
    "    # Entraîner et évaluer le modèle\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_features=mf,\n",
    "        min_samples_leaf=100,\n",
    "        random_state=123,\n",
    "        n_jobs=-1  # Parallélise la construction des arbres\n",
    "    )\n",
    "    score = cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "    # Ajouter les résultats pour tri ultérieur\n",
    "    results.append((mf, num_features, score))\n",
    "\n",
    "# Trier les résultats par ordre croissant du nombre de features\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "# Extraire les labels et scores triés\n",
    "labels = [f\"{mf} ({num_features})\" for mf, num_features, _ in results]\n",
    "scores = [score for _, _, score in results]\n",
    "\n",
    "# Visualisation\n",
    "plt.plot(labels, scores, marker='o')\n",
    "plt.xlabel('max_features (nombre de features)')\n",
    "plt.ylabel('Accuracy moyenne (validation croisée)')\n",
    "plt.title('Influence de max_features')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)  # Incliner les labels pour une meilleure lisibilité\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## Influence de la taille minimale des feuilles (min_samples_leaf)\n",
    "\n",
    "Pour de faibles valeurs du nombre minimum d'observations par feuille (noeud terminal), le modèle risque de sur-ajuster les données d'entraînement; pour des valeurs élevées, le modèle devient plus simple, ce qui peut entraîner un sous-ajustement.\n",
    "\n",
    "L'objectif est donc de trouver un compromis optimal entre ces deux situations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Différentes valeurs de min_samples_leaf à tester\n",
    "min_samples_leaf_range = [5, 10, 50, 100, 500]\n",
    "scores = []\n",
    "\n",
    "for min_samples_leaf in min_samples_leaf_range:\n",
    "        \n",
    "    print(f\"Entraînement en cours avec min_samples_leaf = {min_samples_leaf}\")  # Affichage de la valeur actuelle\n",
    "\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=300,  # Fixé à 500 arbres\n",
    "        max_features='sqrt',\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=123\n",
    "    )\n",
    "    score = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "# Tracer les résultats\n",
    "plt.plot(min_samples_leaf_range, scores, marker='o')\n",
    "plt.xlabel('Valeurs de min_samples_leaf')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Influence de min_samples_leaf')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## Recherche de la meilleure combinaison d'hyperparamètres: Grid Search pour optimiser plusieurs hyperparamètres à la fois\n",
    "\n",
    "GridSearchCV de scikit-learn permet d'optimiser de manière simultanée plusieurs hyperparamètres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### Définition de la grille de paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_leaf': [1, 10, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Mise en place du Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=123),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Exécution du Grid Search\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Résultats du Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "print(\"Meilleure précision :\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "# Evaluer la performance du modèle optimisé par Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Prédictions et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Précision sur le jeu de test :\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance avec une matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=best_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=best_model.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion pour la prédiction du niveau de diplôme\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## Comparaison avec le modèle initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'accuracy sur le jeu de test pour les deux modèles\n",
    "initial_accuracy = rf_model.score(X_test, y_test)\n",
    "optimized_accuracy = best_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Accuracy du modèle initial : {initial_accuracy:.4f}\")\n",
    "print(f\"Accuracy du modèle optimisé : {optimized_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "# Interprétation du modèle : Importance des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## Extraction des importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des variables (Mean Decrease in Impurity)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "## Agrégation des importances pour les variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rassembler l'importance des modalités d'une même variable\n",
    "def calculate_aggregated_importance(X, feature_importances):\n",
    "    \"\"\"\n",
    "    Agrège l'importance des variables catégorielles encodées en colonnes multiples.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Les données d'entraînement (features).\n",
    "        feature_importances (array): Les importances des variables calculées par le modèle.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Importance des variables agrégées par nom de variable.\n",
    "    \"\"\"\n",
    "    # Récupérer les noms des colonnes\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Initialiser un dictionnaire pour stocker les importances agrégées\n",
    "    aggregated_importance = {}\n",
    "\n",
    "    for col in feature_names:\n",
    "        # Identifier les variables spécifiques pour regrouper correctement\n",
    "        if col.startswith('STAT_CONJ_'):\n",
    "            variable = 'STAT_CONJ'\n",
    "        elif col.startswith('STATR_'):\n",
    "            variable = 'STATR'\n",
    "        else:\n",
    "            # Utiliser le préfixe par défaut basé sur le premier segment avant \"_\"\n",
    "            variable = col.split('_')[0]\n",
    "        \n",
    "        # Additionner les importances pour chaque variable \"parent\"\n",
    "        if variable in aggregated_importance:\n",
    "            aggregated_importance[variable] += feature_importances[feature_names.get_loc(col)]\n",
    "        else:\n",
    "            aggregated_importance[variable] = feature_importances[feature_names.get_loc(col)]\n",
    "\n",
    "    # Convertir en DataFrame trié par importance\n",
    "    aggregated_df = pd.DataFrame({\n",
    "        'Variable': aggregated_importance.keys(),\n",
    "        'Importance': aggregated_importance.values()\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appeler la fonction pour regrouper les importances\n",
    "aggregated_importance_df = calculate_aggregated_importance(X, best_model.feature_importances_)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(aggregated_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les libellés des variables depuis le dictionnaire\n",
    "doc_census_individuals_noms_variables = doc_census_individuals[['COD_VAR', 'LIB_VAR']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associer les libellés (descriptions) aux variables d'importance\n",
    "importance_df_with_labels = aggregated_importance_df.merge(\n",
    "    doc_census_individuals_noms_variables,\n",
    "    left_on='Variable',\n",
    "    right_on='COD_VAR',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "## Visualisation des variables les plus importantes\n",
    "La visualisation aide à comprendre quelles variables contribuent le plus à la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour visualiser des n variables les plus importantes\n",
    "def plot_top_n_variables(importance_df, variable_col='Variable', importance_col='Importance', top_n=10):\n",
    "    \"\"\"\n",
    "    Visualise les n variables les plus importantes à partir d'un DataFrame d'importance.\n",
    "\n",
    "    Parameters:\n",
    "    - importance_df (pd.DataFrame): Un DataFrame contenant les colonnes spécifiées.\n",
    "    - variable_col (str): Le nom de la colonne contenant les noms des variables.\n",
    "    - importance_col (str): Le nom de la colonne contenant les valeurs d'importance.\n",
    "    - top_n (int): Le nombre de variables les plus importantes à afficher.\n",
    "    \"\"\"\n",
    "    # Vérifier si les colonnes existent\n",
    "    if variable_col not in importance_df.columns or importance_col not in importance_df.columns:\n",
    "        raise ValueError(f\"Les colonnes '{variable_col}' et/ou '{importance_col}' ne sont pas présentes dans le DataFrame.\")\n",
    "\n",
    "    # Trier par importance décroissante\n",
    "    top_variables = importance_df.sort_values(by=importance_col, ascending=False).head(top_n)\n",
    "\n",
    "    # Création du graphique\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(top_variables[variable_col], top_variables[importance_col], color='steelblue')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Variable\")\n",
    "    plt.title(f\"Top {top_n} variables les plus importantes\")\n",
    "    plt.gca().invert_yaxis()  # Afficher les plus importantes en haut\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des variables les plus importantes\n",
    "plot_top_n_variables(\n",
    "    importance_df = importance_df_with_labels,\n",
    "    variable_col='LIB_VAR',\n",
    "    importance_col='Importance',\n",
    "    top_n=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
