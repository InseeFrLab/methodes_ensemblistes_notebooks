{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Classification binaire: prédire la détention du baccalauréat dans le recensement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Présentation\n",
    "Dans ce tutoriel, nous allons voir comment utiliser une forêt aléatoire en Python avec l'implémentation de `scikit-learn`. Nous présentons les étapes suivantes: la préparation des données, la construction du modèle, l'entraînement du modèle, l'optimisation des hyperparamètres et quelques éléments d'interprétation des résultats.\n",
    "\n",
    "Le jeu de données est issu du recensement de la population (Insee) et contient des informations individuelles issues du recensement, telles que l'âge, le niveau d'éducation, la situation professionnelle, etc. L'objectif sera de prédire si un individu a obtenu le baccalauréat en fonction de ses autres caractéristiques observées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 2. Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 2.1 Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques pour la manipulation des données\n",
    "import os\n",
    "import s3fs\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Bibliothèques pour la visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliothèques pour le traitement des données\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Bibliothèques pour le modèle et l'évaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay, \n",
    "    roc_curve,\n",
    "    RocCurveDisplay,\n",
    "    brier_score_loss,\n",
    "    log_loss,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Pour mesurer le temps d'exécution\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.2 Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la liste des variables à conserver\n",
    "variable_list = [\n",
    "    'AGED', 'APAF', 'CATL', 'CATPC', 'COUPLE', 'CS1', 'DEPT', 'DIPL', \n",
    "    'EMPL', 'HLML', 'ILETUD', 'ILT', 'IMMI', 'INAI', 'INATC', 'INFAM', \n",
    "    'INPER', 'INPERF', 'IRAN', 'LIENF', 'LPRF', 'LPRM', 'METRODOM', 'MOCO',\n",
    "     'MODV', 'NA17', 'NA5', 'NAIDT', 'NBPI', 'NENFR', 'NPERR', 'ORIDT', 'SEXE', \n",
    "     'SFM', 'STAT_CONJ', 'STATR', 'STOCD', 'SURF', 'TACTD16', \n",
    "     'TP', 'TRANS', 'TYPC', 'TYPFC'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ba890-9842-4500-871e-3d03be6f4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se connecter au bucket\n",
    "endpoint = \"https://\"+os.environ['AWS_S3_ENDPOINT']\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': endpoint}, anon=True)\n",
    "\n",
    "# Charger les données individuelles  du recensement\n",
    "with fs.open('s3://oliviermeslin/rp/data_census_individuals.parquet', 'rb') as file:\n",
    "    data_census_individuals = pd.read_parquet(file, columns = variable_list)\n",
    "\n",
    "# Charger la documentation\n",
    "with fs.open('s3://oliviermeslin/rp/metadata_census_individuals.csv', 'rb') as file:\n",
    "    metadata_census_individuals = pd.read_csv(file, delimiter=\";\").query(\"COD_VAR in @variable_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2323ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montrer la liste des variables\n",
    "metadata_census_individuals[[\"COD_VAR\", \"LIB_VAR\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les premières lignes du jeu de données\n",
    "data_census_individuals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 3. Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 3.1 Echantillonnage des données\n",
    "Compte tenu de l'objectif pédagogique de ce tutoriel, nous tirons un échantillon aléatoire de taille restreinte (0,1 % des observations), représentatif de l'ensemble des données initiales, afin d'accélérer les calculs dans les sections suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Échantillonner les données (1/1000)\n",
    "data_sample = data_census_individuals.sample(frac=1/1000, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### 3.2 Création de la variable cible\n",
    "\n",
    "Nous créons la variable que l'on va tâcher de prédire: une variable indicatrice qui vaut 1 pour les individus détenteurs du baccalauréat, 0 pour les autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e46bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir la répartition des classes de diplôme\n",
    "print(data_sample['DIPL'].isna().sum())  # Vérification des valeurs manquantes\n",
    "print(data_sample['DIPL'].value_counts())  # Distribution des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préciser l'odre des catégories de DIPL (ZZ suivi des valeurs numériques croissantes)\n",
    "categories = ['ZZ'] + [f\"{i:02}\" for i in range(1, 20)]\n",
    "data_sample['DIPL'] = pd.Categorical(data_sample['DIPL'], categories=categories, ordered=True)\n",
    "\n",
    "# Créer la variable binaire 'bac'\n",
    "data_sample['bac'] = (data_sample['DIPL'] > '13').astype(int)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(data_sample[['DIPL', 'bac']].head(20))\n",
    "print(data_sample['bac'].value_counts())  # Distribution des classes\n",
    "\n",
    "# Supprimer la colonne 'DIPL' du DataFrame (car c'est un prédicteur parfait du baccalauréat)\n",
    "data_sample = data_sample.drop(columns=['DIPL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 3.3 Préparation des variables explicatives (_features_)\n",
    "Dans un premier temps, on transforme en variables continues toutes les variables catégorielles qui peuvent l'être. Certaines variables catégorielles comportent un ordre naturel, mais comprennent également une modalité \"X\" ou \"Z\" correspondant à une valeur manquante (ou non pertinente). Nous remplaçons cette modalité par une valeur numérique extrême (99 ou 999), ce qui permet de convertir la variable en variable continue.\n",
    "\n",
    "_A TERME: lien avec la partie du document de travail relative à la préparation des données._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dupliquer la table de données avant de retraiter les features\n",
    "data_clean = copy.deepcopy(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une fonction qui teste si une chaîne de caractères peut être convertie en un entier\n",
    "def can_convert_to_int(value):\n",
    "    try:\n",
    "        int(value)  # Attempt to convert the value to an integer\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c585455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer en variables continues toutes les variables qui peuvent l'être\n",
    "for var in data_clean.columns.tolist():\n",
    "    if data_clean[var].dtype.name == \"category\":\n",
    "        if set([category for category in data_clean[var].cat.categories if not can_convert_to_int(category)]) <= set(['X', 'Z']):\n",
    "            data_clean[var] = data_clean[var].cat.rename_categories({'X': '99', 'Z': '999'})\n",
    "            data_clean[var] = data_clean[var].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79031b63",
   "metadata": {},
   "source": [
    "Dans un deuxième temps, on  applique un _one-hot-encoding_ aux variables catégorielles, avec la fonction [`OneHotEncoder()`](https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OneHotEncoder.html) de `scikit`. On applique ce préprocessing avec la fonction  [`ColumnTransformer()`](https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html), qui réduit les traitements manuels et permet de traiter tout le jeu de données en une fois. On utilise la fonction [`make_column_selector()`](https://scikit-learn.org/1.5/modules/generated/sklearn.compose.make_column_selector.html) permet d'appliquer le bon _preprocessing_ en fonction du type des variables, sans avoir à en faire une liste explicite.  On n'applique aucune transformation aux variables numériques car les méthodes ensemblistes sont invariantes aux transformations monotones des _features_. On utilise donc l'option `\"passthrough\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4488be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding des variables catégorielles\n",
    "preprocessor  = ColumnTransformer( \n",
    "    [('encoder', OneHotEncoder(drop = None, handle_unknown='error'), make_column_selector(dtype_include=[\"category\", \"object\"]))], \n",
    "    remainder='passthrough', \n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold = 0\n",
    ")\n",
    "\n",
    "# Fitter le preprocessor\n",
    "preprocessor.fit(data_clean) \n",
    "\n",
    "# Transformer les données avec le préprocessor fitté\n",
    "data_clean2 = pd.DataFrame(preprocessor.transform(data_clean), columns = preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c409e",
   "metadata": {},
   "source": [
    "On sépare enfin les _features_ et la variable-cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les features (X) et la variable cible (y : bac)\n",
    "X = data_clean2.drop(columns=['bac'])\n",
    "y = data_clean['bac']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 3.4 Séparation des ensembles d'entraînement et de test\n",
    "On utilise la fonction [`train_test_split()`](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html) pour séparer l'ensemble d'entraînement et l'ensemble de test. La stratification en fonction de $y$ assure que la proportion des classes est la même dans les ensembles d'entraînement et de test. On rappelle qu'un ensemble de test n'est pas absolument nécessaire pour évaluer une forêt aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement (80%) et de test (20%) avec stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## 4. Entraîner une première forêt aléatoire \n",
    "Dans cette section, nous allons entraîner une toute première forêt avec les __hyperparamètres par défaut__. Il est important de noter que ces valeurs par défaut varie d'une implémentation à l'autre. Dans `scikit-learn`, [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) a les valeurs par défaut suivantes:\n",
    "\n",
    "|Hyperparamètre | Signification | Valeur par défaut |\n",
    "|:----:|----|:----:|\n",
    "| `n_estimators`           | Nombre d'arbres dans la forêt | 100 |\n",
    "| `max_features`           | Nombre de variables à considérer pour déterminer le meilleur _split_ | 'sqrt'|\n",
    "| `max_samples`            | La taille des échantillons aléatoires                                         | `n` |\n",
    "| `min_samples_leaf`       | Nombre minimum d'échantillons dans une feuille terminale | 1 |\n",
    "| `min_samples_split`      | Nombre minimal d'observations nécessaire pour qu'un noeud puisse être partagé | 2 |\n",
    "| `criterion`              | Le critère de choix de la règle de division des noeuds intermédiaires         | 'gini' |\n",
    "| `max_depth`              | Profondeur maximale des arbres                                                | None |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### 4.1 Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b3ec9",
   "metadata": {},
   "source": [
    "On commence par créer un modèle en faisant appel à la fonction `RandomForestClassifier()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a29beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle\n",
    "rf_default_settings = RandomForestClassifier(random_state=42, n_jobs=-1, oob_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "start_time = time.time()\n",
    "rf_default_settings.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Temps d'entraînement du modèle Random Forest : {elapsed_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 4.2 Evaluation sur le jeu de test\n",
    "\n",
    "La matrice de confusion permet de visualiser les erreurs de classification.\n",
    "Le rapport de classification donne des métriques importantes comme la précision, le rappel et le F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred_baseline = rf_default_settings.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance avec une matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_baseline, labels=rf_default_settings.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=rf_default_settings.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion pour la prédiction de la détention du baccalauréat\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da08d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représenter la ROC curve\n",
    "RocCurveDisplay.from_estimator(rf_default_settings, X_test, y_test, name=\"Baseline model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## 5. Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd268d",
   "metadata": {},
   "source": [
    "Dans cette section, nous allons suivre pas à pas la procédure d'entraînement des forêts aléatoires détaillée [ici](https://oliviermeslin.github.io/DT_methodes_ensemblistes/chapters/chapter3/2-guide_usage_RF.html). Nous allons donc aborder les étapes suivantes:\n",
    "\n",
    "- Choisir le bon nombre d'arbres (`n_estimators`);\n",
    "- Explorer l'espaces des valeurs possibles pour `min_samples_leaf` avec un _grid search_ (par validation croisée et par l'approche OOB);\n",
    "- Explorer l'espaces des valeurs possibles pour `max_features` (alias de `mtry`) et `max_samples` avec un _grid search_;\n",
    "- Evaluer l'apport de cette optimisation des hyperparamètres en comparant le modèle final à un modèle reposant sur les valeurs par défaut des hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### 5.1 Choisir le nombre d'arbres (`n_estimators`)\n",
    "\n",
    "Le nombre d'arbres d'une forêt aléatoire est un hyperparamètre particulier car il n'est associé à aucun arbitrage en matière de performance: la performance de la forêt aléatoire croît avec le nombre d'arbres, puis se stabilise à un niveau approximativement constant. Le nombre optimal d'arbres est donc intuitivement celui à partir duquel la performance de la forêt ne croît plus: il en faut \"assez\", mais pas \"trop\", d'autant qu'un nombre d'arbre élevé peut allonger considérablement le temps de calcul.\n",
    "\n",
    "La méthode proposée pour choisir le nombre d'arbre est la suivante:\n",
    "\n",
    "- on entraîne une forêt aléatoire avec les hyperparamètres par défaut, en augmentant progressivement le nombre d'arbres;\n",
    "- on calcule à chaque étape le taux d'erreur _out-of-bag_ du modèle en fonction du nombre d'arbres, en utilisant le [score de Brier](https://scikit-learn.org/dev/modules/model_evaluation.html#common-cases-predefined-values) comme métrique;\n",
    "- on représente graphiquement ce taux d'erreur en fonction du nombre d'arbres;\n",
    "- le nombre d'arbres optimal est celui à partir duquel le taux d'erreur ne diminue plus.\n",
    "\n",
    "Deux remarques sur cette approche:\n",
    "\n",
    "- Cette approche n'est pas parfaite, car le nombre optimal d'arbres dépend de la valeur des autres hyperparamètres, mais elle a le mérite d'être simple et rapide. \n",
    "- Il est possible d'appliquer cette approche avec une autre métrique que le score de Brier. La liste des métriques disponibles dans `scikit-learn` est [ici](https://scikit-learn.org/dev/modules/model_evaluation.html#common-cases-predefined-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ce code est inspiré de celui-ci: https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "\n",
    "# Créer un modèle avec les hyperparamètres par défaut\n",
    "# NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
    "# support for parallelized ensembles but is necessary for tracking the OOB\n",
    "# error trajectory during training.\n",
    "rf_nb_trees = RandomForestClassifier(\n",
    "    oob_score=brier_score_loss, # Ici il est possible de choisir une autre métrique pour calculer l'erreur OOB\n",
    "    warm_start=True,\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Préparer un dictionnaire pour stocker les résultats\n",
    "error_rate = dict()\n",
    "\n",
    "# Définir l'intervalle de valeurs à explorer\n",
    "min_estimators = 40\n",
    "max_estimators = 500\n",
    "increment_size = 20\n",
    "\n",
    "# Entraîner le modèle en augmentant le nombe d'arbres\n",
    "for n_trees in range(min_estimators, max_estimators + 1, increment_size):\n",
    "    print(n_trees)\n",
    "\n",
    "    # Définir le nombre d'arbres\n",
    "    rf_nb_trees.set_params(n_estimators=n_trees)\n",
    "    rf_nb_trees.fit(X_train, y_train)\n",
    "\n",
    "    # Conserver le taux d'erreur du modèle\n",
    "    error_rate[n_trees] = rf_nb_trees.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représenter graphiquement le taux d'erreur en fonction du nombre d'arbres\n",
    "x, y = zip(*sorted(error_rate.items()))\n",
    "plt.plot(x, y)\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"Nombre d'arbres\")\n",
    "plt.ylabel(f\"Taux d'erreur OOB (métrique = {rf_nb_trees.oob_score.__name__})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb742cc",
   "metadata": {},
   "source": [
    "On voit que la performance croît nettement avec le nombre d'arbres au début, puis se stabilise progressivement. La performance ne s'améliore plus au-delà de 400 arbres: on retient donc la valeur de 400 arbres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### 5.2 Choisir le taux d'échantillonnage (`max_samples`) et la proportion de variables candidates (`max_features`)\n",
    "\n",
    "Nous allons maintenant choisir le taux d'échantillonnage et la proportion de variables candidates. Pour ce faire, nous allons explorer l'espace des valeurs possibles pour ces hyperparamètres, selon deux approches:\n",
    "\n",
    "- Une approche par validation croisée avec la fonction `GridSearchCV`;\n",
    "- Une approche par l'erreur OOB.\n",
    "\n",
    "Deux points importants sont à noter:\n",
    "\n",
    "- l'approche par validation croisée est intense en calcul, mais est complètement standard et applicable à tous les algorithmes de _machine learning_ supervisé. Inversement, __l'approche par l'ereur OOB est plus rapide, mais elle est exclusivement applicable aux forêts aléatoires__ et ne peut pas être utilisée avec d'autres algorithmes. Par ailleurs, elle est beaucoup moins bien (voire pas) documentée sur internet.\n",
    "- si vous testez un grand nombre de valeurs possibles pour les hyperparamètres par validation croisée, le temps de calcul peut devenir très long!\n",
    "\n",
    "Nous utilisons un modèle avec les hyperparamètres choisis jusqu'ici: `n_estimators = 400`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROCHE 1: Validation croisée\n",
    "\n",
    "# Créer un modèle avec 400 arbres, et tous les autres hyperparamètres par défaut\n",
    "rf_crossval = RandomForestClassifier(\n",
    "    n_estimators = 400,\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Définir la grille d'hyperparamètres\n",
    "param_grid = {\n",
    "    # Taux d'échantillonnage\n",
    "    'max_samples': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    # Nombre de features candidates à chaque split \n",
    "    'max_features': ['sqrt', 0.6, 0.8, None] # None revient à faire du bagging\n",
    "}\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_crossval,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                         # Validation croisée à 5 plis\n",
    "    scoring='neg_brier_score',    # Métrique à optimiser\n",
    "    n_jobs=-1,                    # Utiliser tous les cœurs disponibles\n",
    "    verbose=1,                    # Afficher la progression\n",
    "    refit=True                    # Réentrainer le modèle avec les meilleurs paramètres\n",
    ")\n",
    "\n",
    "# Exécuter la recherche\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres\n",
    "print(\"Best parameters found:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa486528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROCHE 2: approche OOB\n",
    "# ATTENTION: cette approche est applicable exclusivement aux forêts aléatoires\n",
    "\n",
    "# Créer une variable pour conserver le score\n",
    "best_score = np.inf\n",
    "\n",
    "# Créer un modèle avec 400 arbres, et tous les autres hyperparamètres par défaut\n",
    "rf_oob = RandomForestClassifier(\n",
    "    n_estimators = 400,\n",
    "    oob_score=brier_score_loss, # Ici il est possible de choisir une autre métrique pour calculer l'erreur OOB\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Définir la grille d'hyperparamètres\n",
    "param_grid = {\n",
    "    # Taux d'échantillonnage\n",
    "    'max_samples': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    # Nombre de features candidates à chaque split \n",
    "    'max_features': ['sqrt', 0.6, 0.8, None] # None revient à faire du bagging\n",
    "}\n",
    "\n",
    "# Entraîner le modèle et calculer l'erreur OOB avec la métrique choisie\n",
    "for g in ParameterGrid(param_grid):\n",
    "    print(g)\n",
    "    rf_oob.set_params(**g)\n",
    "    rf_oob.fit(X_train,y_train)\n",
    "    # save if best\n",
    "    if rf_oob.oob_score_ < best_score:\n",
    "        best_score = rf_oob.oob_score_\n",
    "        best_params = g\n",
    "\n",
    "print(\"Meilleurs hyperparamètres:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7217e5",
   "metadata": {},
   "source": [
    "Les deux approches donnent des résultats différents mais très proches: `max_features = 0.6` et `max_samples = 0.5` pour l'approche par validation croisée et `max_features = 0.6` et `max_samples = 0.6` pour l'approche OOB. On retient donc les valeurs `max_features = 0.6` et `max_samples = 0.5`. A noter que dans l'approche par validation croisée, le modèle avec les meilleurs hyperparamètres est déjà entraîné grâce à l'option `refit=True`, et on peut donc l'utiliser directement (il est stocké dans `grid_search.best_estimator_`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa0c43",
   "metadata": {},
   "source": [
    "On peut maintenant évaluer le modèle obtenu sur les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred2 = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2bf2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance avec une matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred2, labels=best_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=best_model.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion pour la prédiction de la détention du baccalauréat\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd49e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer le meilleur modèle sur les données de test\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf8a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représenter la ROC curve\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test, name=\"Model 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### 5.3 Choisir la taille minimale des feuilles (`min_samples_leaf`)\n",
    "\n",
    "Pour de faibles valeurs du nombre minimum d'observations par feuille (noeud terminal), le modèle risque de sur-ajuster les données d'entraînement; pour des valeurs élevées, le modèle devient plus simple, ce qui peut entraîner un sous-ajustement. Cet hyperparamètre n'est pas le plus important en terme de performance, mais il a une influence majeure sur le temps d'entraînement du modèle: une valeur faible implique des arbres profonds donc longs à entraîner. Il peut donc parfois être utile de vérifier assez tôt dans la procédure d'entraînement s'il est possible de le fixer à une valeur plus élevée que la valeur par défaut sans perte de performance, pour accélérer le reste de la procédure. Ceci dit, il faut garder en tête que la valeur optimale de cet hyperparamètre peut dépendre des autres hyperparamètres.\n",
    "\n",
    "On optimise cet hyperparamètre en explorant ses valeurs possibles, selon deux approches:\n",
    "\n",
    "- Une approche par validation croisée avec la fonction `GridSearchCV`;\n",
    "- Une approche par l'erreur OOB.\n",
    "\n",
    "Nous utilisons un modèle avec les hyperparamètres choisis jusqu'ici: `n_estimators = 400`, `max_features = 0.6` et `max_samples = 0.5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3dbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROCHE 1: Validation croisée\n",
    "\n",
    "# Créer un modèle avec 400 arbres, max_features = 0.6 et max_samples = 0.7\n",
    "rf_crossval_leaf_size = RandomForestClassifier(\n",
    "    n_estimators = 400,\n",
    "    max_features = 0.6,\n",
    "    max_samples = 0.5,\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Définir la grille d'hyperparamètres\n",
    "param_grid_leaf_size = {\n",
    "    # Taille minimale des feuilles\n",
    "    'min_samples_leaf': [1, 3, 5, 10, 20, 50, 100, 200, 500]\n",
    "}\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "grid_search_leaf_size = GridSearchCV(\n",
    "    estimator=rf_crossval_leaf_size,\n",
    "    param_grid=param_grid_leaf_size ,\n",
    "    cv=5,                         # Validation croisée à 5 plis\n",
    "    scoring='neg_brier_score',    # Métrique à optimiser\n",
    "    n_jobs=-1,                    # Utiliser tous les cœurs disponibles\n",
    "    verbose=1,                    # Afficher la progression\n",
    "    refit=True                    # Réentrainer le modèle avec les meilleurs paramètres\n",
    ")\n",
    "\n",
    "# Exécuter la recherche\n",
    "grid_search_leaf_size.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres\n",
    "print(\"Best parameters found:\", grid_search_leaf_size.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf88dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROCHE 2: approche OOB\n",
    "# ATTENTION: cette approche est applicable exclusivement aux forêts aléatoires\n",
    "\n",
    "# Créer une variable pour conserver le score\n",
    "best_score_leaf_size = np.inf\n",
    "\n",
    "# Créer un modèle avec 400 arbres, max_features = 0.6 et max_samples = 0.7\n",
    "rf_oob_leaf_size = RandomForestClassifier(\n",
    "    n_estimators = 400,\n",
    "    max_features = 0.6,\n",
    "    max_samples = 0.5,\n",
    "    oob_score=brier_score_loss, # Ici il est possible de choisir une autre métrique pour calculer l'erreur OOB\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Définir la grille d'hyperparamètres\n",
    "param_grid_leaf_size = {\n",
    "    # Taille minimale des feuilles\n",
    "    'min_samples_leaf': [1, 3, 5, 10, 20, 50, 100, 200, 500]\n",
    "}\n",
    "\n",
    "for g in ParameterGrid(param_grid_leaf_size):\n",
    "    print(g)\n",
    "    rf_oob_leaf_size.set_params(**g)\n",
    "    rf_oob_leaf_size.fit(X_train,y_train)\n",
    "    print(rf_oob_leaf_size.oob_score_)\n",
    "    # save if best\n",
    "    if rf_oob_leaf_size.oob_score_ < best_score:\n",
    "        best_score = rf_oob_leaf_size.oob_score_\n",
    "        best_params = g\n",
    "\n",
    "print(\"OOB: %0.5f\" % best_score) \n",
    "print(\"Best parameters found:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb64967",
   "metadata": {},
   "source": [
    "Les deux approches donnent à nouveau des résultats différents mais très proches: `min_samples_leaf = 5` et `min_samples_leaf = 3`,  soit des valeurs légèrement plus élevées que la valeur par défaut. On retient `min_samples_leaf = 5`. Le script suivant illustre l'influence de cet hyperparamètre sur la performance du modèle, mesurée par l'aire sous la courbe ROC. On voit bien qu'il y a un arbitrage entre des valeurs faibles (qui aboutissent à des arbres très profonds qui surajustent les données) et des valeurs élevées (qui aboutissent à des arbres trop simples et peu performants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafcc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Différentes valeurs de min_samples_leaf à tester\n",
    "min_samples_leaf_range = [1, 3, 5, 10, 20, 50, 100]\n",
    "scores = []\n",
    "\n",
    "for value_min_samples_leaf in min_samples_leaf_range:\n",
    "        \n",
    "    print(f\"Entraînement en cours avec min_samples_leaf = {value_min_samples_leaf}\")  # Affichage de la valeur actuelle\n",
    "\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators = 400,\n",
    "        max_features = 0.6,\n",
    "        max_samples = 0.5,\n",
    "        min_samples_leaf=value_min_samples_leaf,\n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    score = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "# Tracer les résultats\n",
    "plt.plot(min_samples_leaf_range, scores, marker='o')\n",
    "plt.xlabel('Valeurs de min_samples_leaf')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Influence de min_samples_leaf')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f327ab3",
   "metadata": {},
   "source": [
    "### 5.4 Comparaison du modèle initial et du modèle final\n",
    "Nous pouvons maintenant comparer les performances relatives du modèle de base (avec les hyperparamètres par défaut) et du modèle final (avec des hyperparamètres optimisés)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cfebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle final\n",
    "rf_final = RandomForestClassifier(\n",
    "    n_estimators = 400,\n",
    "    max_features = 0.6,\n",
    "    max_samples = 0.5,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_final.fit(X_train, y_train)\n",
    "\n",
    "# Calculer les prédictions du modèle final sur les données de test\n",
    "y_pred_final = rf_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c471ca",
   "metadata": {},
   "source": [
    "Si l'on compare les rapports de classification et les courbes ROC, on constate que le modèle final est légèrement plus performant que le modèle de base. Cette différence de performance est toutefois réduite, surtout si l'on prend en compte le temps que nous avons passé à optimiser les hyperparamètres. \n",
    "\n",
    "Ceci dit, __il est important de souligner que nous avons travaillé sur un jeu de données de taille réduite__; il est tout à fait possible qu'avec un jeu de données plus conséquent l'optimisation des hyperparamètres aboutisse à des valeurs différentes des hyperparamètres, et que le gain de performance soit plus important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd4f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred_baseline))\n",
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d19fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les ROC curves\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "for (model, c, name) in zip(\n",
    "    (rf_default_settings, rf_final),\n",
    "     ('r', 'b'),\n",
    "     ('Modèle de base',\n",
    "      'Modèle final')\n",
    "    ):\n",
    "    RocCurveDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        name=name,\n",
    "        ax=ax,\n",
    "        color=c\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## 6. Interprétation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### 6.1 Importance des variables\n",
    "L'importance des variables (_feature importance_) reflète leur contribution à la qualité des prédictions du modèle. Parmi les différentes mesures disponibles, nous utilisons ici la \"Mean Decrease in Impurity\" (MDI). Cette métrique évalue la contribution de chaque variable à la réduction de l'impureté moyenne dans l'arbre de décision. \n",
    "Pour chaque variable, elle correspond à la moyenne des réductions d’impureté (par exemple, l'indice de Gini ou l'entropie) qu’elle a engendrées dans tous les nœuds de tous les arbres où elle est impliquée. Les variables présentant la réduction moyenne d’impureté la plus élevée sont considérées comme les prédicteurs les plus importants.\n",
    "\n",
    "_A TERME: un renvoi vers la partie du DT qui présente les mesures d'importance et leurs limites._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des variables (Mean Decrease in Impurity)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Variable': X_train.columns,\n",
    "    'Importance': rf_final.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f31f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c655701",
   "metadata": {},
   "source": [
    "Dans le tableau précédent, on peut voir que les variables ayant l'importance la plus élevée sont conformes à l'intuition: l'âge, la catégorie socioprofessionnelle et le type d'activité détaillé. On peut également noter la présence de variables indicatrices issues du _one-hot-encoding_ (comme `STOCD_22`) qui sont plus délicates à interpréter, car elles correspondent uniquement à une modalité d'une certaine variable catégorielle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "Une approche permettant de rendre plus lisible l'importance des variables catégorielles consiste à agréger l'importance de leurs modalités en les sommant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rassembler l'importance des modalités d'une même variable\n",
    "def calculate_aggregated_importance(raw_feature_names, feature_names, feature_importances):\n",
    "    \"\"\"\n",
    "    Agrège l'importance des variables catégorielles encodées en colonnes multiples.\n",
    "\n",
    "    Args:\n",
    "        raw_feature_names (array): nom des données brutes avant préprocessing.\n",
    "        feature_names (array): nom des données d'entraînement (features).\n",
    "        feature_importances (array): Les importances des variables calculées par le modèle.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Importance des variables agrégées par nom de variable.\n",
    "    \"\"\"\n",
    "    # Récupérer les noms des colonnes\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Initialiser un dictionnaire pour stocker les importances agrégées\n",
    "    aggregated_importance = {}\n",
    "\n",
    "    for col in feature_names:\n",
    "        # Identifier les variables spécifiques pour regrouper correctement\n",
    "        if col in raw_feature_names:\n",
    "                variable = col\n",
    "        else:\n",
    "            # Utiliser le préfixe par défaut basé sur le premier segment avant \"_\"\n",
    "            variable = col.split('_')[0]\n",
    "        \n",
    "        # Additionner les importances pour chaque variable \"parent\"\n",
    "        if variable in aggregated_importance:\n",
    "            aggregated_importance[variable] += feature_importances[feature_names.get_loc(col)]\n",
    "        else:\n",
    "            aggregated_importance[variable] = feature_importances[feature_names.get_loc(col)]\n",
    "\n",
    "    # Convertir en DataFrame trié par importance\n",
    "    aggregated_df = pd.DataFrame({\n",
    "        'Variable': aggregated_importance.keys(),\n",
    "        'Importance': aggregated_importance.values()\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les noms des colonnes\n",
    "feature_names = X_train.columns\n",
    "raw_feature_names = data_sample.drop(\"bac\", axis = 1).columns\n",
    "\n",
    "# Appeler la fonction pour regrouper les importances\n",
    "aggregated_importance_df = calculate_aggregated_importance(raw_feature_names, feature_names, rf_final.feature_importances_)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(aggregated_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b780e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les libellés des variables depuis le dictionnaire\n",
    "doc_census_individuals_noms_variables = doc_census_individuals[['COD_VAR', 'LIB_VAR']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associer les libellés (descriptions) aux variables d'importance\n",
    "importance_df_with_labels = aggregated_importance_df.merge(\n",
    "    doc_census_individuals_noms_variables,\n",
    "    left_on='Variable',\n",
    "    right_on='COD_VAR',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "## Visualisation des variables les plus importantes\n",
    "La visualisation aide à comprendre quelles variables contribuent le plus à la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour visualiser les n variables les plus importantes\n",
    "def plot_top_n_variables(importance_df, variable_col='Variable', importance_col='Importance', top_n=10):\n",
    "    \"\"\"\n",
    "    Visualise les n variables les plus importantes à partir d'un DataFrame d'importance.\n",
    "\n",
    "    Parameters:\n",
    "    - importance_df (pd.DataFrame): Un DataFrame contenant les colonnes spécifiées.\n",
    "    - variable_col (str): Le nom de la colonne contenant les noms des variables.\n",
    "    - importance_col (str): Le nom de la colonne contenant les valeurs d'importance.\n",
    "    - top_n (int): Le nombre de variables les plus importantes à afficher.\n",
    "    \"\"\"\n",
    "    # Vérifier si les colonnes existent\n",
    "    if variable_col not in importance_df.columns or importance_col not in importance_df.columns:\n",
    "        raise ValueError(f\"Les colonnes '{variable_col}' et/ou '{importance_col}' ne sont pas présentes dans le DataFrame.\")\n",
    "\n",
    "    # Trier par importance décroissante\n",
    "    top_variables = importance_df.sort_values(by=importance_col, ascending=False).head(top_n)\n",
    "\n",
    "    # Création du graphique\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(top_variables[variable_col], top_variables[importance_col], color='steelblue')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Variable\")\n",
    "    plt.title(f\"Top {top_n} variables les plus importantes\")\n",
    "    plt.gca().invert_yaxis()  # Afficher les plus importantes en haut\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des variables les plus importantes\n",
    "plot_top_n_variables(\n",
    "    importance_df = importance_df_with_labels,\n",
    "    variable_col='LIB_VAR',\n",
    "    importance_col='Importance',\n",
    "    top_n=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ccecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer le meilleur modèle sur les données de test\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred2 = best_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
