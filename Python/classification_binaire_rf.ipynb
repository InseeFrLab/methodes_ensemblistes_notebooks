{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Classification binaire: prédire la détention du baccalauréat dans le recensement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Présentation\n",
    "Dans ce tutoriel, nous allons voir comment utiliser une forêt aléatoire en Python avec l'implémentation de `scikit-learn`. Cet algorithme est présenté en détail dans le document de travail ([ici](https://inseefrlab.github.io/DT_methodes_ensemblistes/chapters/chapter2/3-random_forest.html)).\n",
    "\n",
    "Ce tutoriel se concentre donc sur la mise en oeuvre pratique de l'algorithme. Nous présentons les étapes suivantes: la préparation des données, la construction du modèle, l'entraînement du modèle, l'optimisation des hyperparamètres et quelques éléments d'interprétation des résultats.\n",
    "\n",
    "Le jeu de données est issu du recensement de la population (Insee) et contient des informations individuelles issues du recensement, telles que l'âge, le niveau d'éducation, la situation professionnelle, etc. L'objectif sera de prédire si un individu a obtenu le baccalauréat en fonction de ses autres caractéristiques observées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 2. Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 2.1 Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques pour la manipulation des données\n",
    "import os\n",
    "import s3fs\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Bibliothèques pour la visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Bibliothèques pour le traitement des données\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Bibliothèques pour le modèle et l'évaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay, \n",
    "    roc_curve,\n",
    "    RocCurveDisplay,\n",
    "    brier_score_loss,\n",
    "    log_loss,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Pour mesurer le temps d'exécution\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.2 Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la liste des variables à conserver\n",
    "variable_list = [\n",
    "    'AGED', 'APAF', 'CATL', 'CATPC', 'COUPLE', 'CS1', 'DEPT', 'DIPL', \n",
    "    'EMPL', 'HLML', 'ILETUD', 'ILT', 'IMMI', 'INAI', 'INATC', 'INFAM', \n",
    "    'INPER', 'INPERF', 'IRAN', 'LIENF', 'LPRF', 'LPRM', 'METRODOM', 'MOCO',\n",
    "     'MODV', 'NA17', 'NA5', 'NAIDT', 'NBPI', 'NENFR', 'NPERR', 'ORIDT', 'SEXE', \n",
    "     'SFM', 'STAT_CONJ', 'STATR', 'STOCD', 'SURF', 'TACTD16', \n",
    "     'TP', 'TRANS', 'TYPC', 'TYPFC'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ba890-9842-4500-871e-3d03be6f4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se connecter au bucket\n",
    "endpoint = \"https://\"+os.environ['AWS_S3_ENDPOINT']\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': endpoint}, anon=True)\n",
    "\n",
    "# Charger les données individuelles  du recensement\n",
    "with fs.open('s3://oliviermeslin/rp/data_census_individuals.parquet', 'rb') as file:\n",
    "    data_census_individuals = pd.read_parquet(file, columns = variable_list)\n",
    "\n",
    "# Charger la documentation\n",
    "with fs.open('s3://oliviermeslin/rp/metadata_census_individuals.csv', 'rb') as file:\n",
    "    doc_census_individuals = pd.read_csv(file, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 3. Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 3.1 Echantillonnage des données\n",
    "Compte tenu de l'objectif pédagogique de ce tutoriel, nous tirons un échantillon aléatoire de taille restreinte (0,2 % des observations), représentatif de l'ensemble des données initiales, afin d'accélérer les calculs dans les sections suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Échantillonner les données (1/200)\n",
    "data_sample = data_census_individuals.sample(frac=1/500, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### 3.2 Création de la variable cible\n",
    "\n",
    "Nous créons la variable que l'on va tâcher de prédire: une variable indicatrice qui vaut 1 pour les individus détenteurs du baccalauréat, 0 pour les autres. Un point important est que les deux classes sont approximativement équilibrées, il n'est donc pas nécessaire d'utiliser des pondérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e46bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir la répartition des classes de diplôme\n",
    "print(data_sample['DIPL'].isna().sum())  # Vérification des valeurs manquantes\n",
    "print(data_sample['DIPL'].value_counts())  # Distribution des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e46bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préciser l'odre des catégories de DIPL (ZZ suivi des valeurs numériques croissantes)\n",
    "categories = ['ZZ'] + [f\"{i:02}\" for i in range(1, 20)]\n",
    "data_sample['DIPL'] = pd.Categorical(data_sample['DIPL'], categories=categories, ordered=True)\n",
    "\n",
    "# Créer la variable binaire 'bac'\n",
    "data_sample['bac'] = (data_sample['DIPL'] > '13').astype(int)\n",
    "\n",
    "# Afficher le résultat: les deux classes sont approximativement équilibrées\n",
    "print(data_sample['bac'].value_counts())  # Distribution des classes\n",
    "\n",
    "# Supprimer la colonne 'DIPL' du DataFrame (car c'est un prédicteur parfait du baccalauréat)\n",
    "data_sample = data_sample.drop(columns=['DIPL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### 3.3 Préparation des variables explicatives (_features_)\n",
    "Dans un premier temps, on transforme en variables continues toutes les variables catégorielles qui peuvent l'être. Certaines variables catégorielles comportent un ordre naturel, mais comprennent également une modalité \"X\" ou \"Z\" correspondant à une valeur manquante (ou non pertinente). Nous remplaçons cette modalité par une valeur numérique extrême (99 ou 999), ce qui permet de convertir la variable en variable continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dupliquer la table de données avant de retraiter les features\n",
    "data_clean = copy.deepcopy(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une fonction qui teste si une chaîne de caractères peut être convertie en un entier\n",
    "def can_convert_to_int(value):\n",
    "    try:\n",
    "        int(value)  # Attempt to convert the value to an integer\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer en variables continues toutes les variables qui peuvent l'être\n",
    "for var in data_clean.columns.tolist():\n",
    "    if data_clean[var].dtype.name == \"category\":\n",
    "        if set([category for category in data_clean[var].cat.categories if not can_convert_to_int(category)]) <= set(['X', 'Z', 'ZZ']):\n",
    "            data_clean[var] = data_clean[var].cat.rename_categories({'X': '99', 'Z': '999', 'ZZ': '9999'})\n",
    "            data_clean[var] = data_clean[var].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c585455",
   "metadata": {},
   "source": [
    "On sépare enfin les _features_ et la variable-cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les features (X) et la variable cible (y : bac)\n",
    "X = data_clean2.drop(columns=['bac'])\n",
    "y = data_clean['bac']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 3.4 Séparation des ensembles d'entraînement et de test\n",
    "On utilise la fonction [`train_test_split()`](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html) pour séparer l'ensemble d'entraînement et l'ensemble de test. La stratification en fonction de $y$ assure que la proportion des classes est la même dans les ensembles d'entraînement et de test. On rappelle qu'un ensemble de test n'est pas absolument nécessaire pour évaluer une forêt aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement (80%) et de test (20%) avec stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e936df",
   "metadata": {},
   "source": [
    "## 4. Construire le modèle complet\n",
    "\n",
    "Nous allons construire le modèle complet en utilisant __un _pipeline_ `scikit-learn`, dont l'usage est très fortement recommandé__. Ce _pipeline_ va comprendre deux étapes: le _preprocessing_ des données, puis la forêt aléatoire proprement dite.\n",
    "\n",
    "Un _pipeline_ `scikit-learn` est un objet informatique qui permet d'assurer une exécution cohérente de plusieurs étapes de traitement des données. Par exemple, un _pipeline_ permet de réaliser la normalisation des variables, le traitement des valeurs manquantes, l'encodage des variables catégorielles, et l'entraînement d'un modèle __en une seule étape__. Utiliser un _pipeline_ simplifie les codes et garantit que les mêmes transformations sont appliquées aux données d'entraînement et de test, ce qui réduit le risque d'erreur et augmente la reproductibilité des résultats. Si vous n'êtes pas habitué à les utiliser, il est fortement recommandé de lire la [documentation officielle sur ce sujet](https://scikit-learn.org/1.5/modules/compose.html) et l'[excellente formation](https://pythonds.linogaliana.fr/content/modelisation/6_pipeline.html) de Lino Galiana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b5b69",
   "metadata": {},
   "source": [
    "### 4.1 Le préprocessing des données\n",
    "Le _préprocessing_ des données est construit avec la fonction  [`ColumnTransformer()`](https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html) de `scikit` et n'est pas le même selon le type des variables:\n",
    "- on applique un _one-hot-encoding_ aux variables catégorielles, avec la fonction [`OneHotEncoder()`](https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OneHotEncoder.html) de `scikit`. On choisit d'encoder toutes les modalités (`drop=None`). L'option `handle_unknown='error'` signifie que le modèle renverra une erreur s'il rencontre une modalité inconnue lors de l'utilisation en prédiction.\n",
    "- On applique aucune transformation aux variables numériques car les méthodes ensemblistes sont invariantes aux transformations monotones des _features_. On utilise donc l'option \"passthrough\".\n",
    "\n",
    "On utilise la fonction [`make_column_selector()`](https://scikit-learn.org/1.5/modules/generated/sklearn.compose.make_column_selector.html) permet d'appliquer le bon _preprocessing_ en fonction du type des variables, sans avoir à en faire une liste explicite.\n",
    "\n",
    "Pour plus d'explications, vous pouvez lire la partie du document de travail sur la [préparation des données](https://inseefrlab.github.io/DT_methodes_ensemblistes/chapters/chapter3/1-preparation_donnees.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire la première étape du pipeline (préprocessing des données)\n",
    "\n",
    "# One-hot-encoding des variables catégorielles\n",
    "preprocessor  = ColumnTransformer( \n",
    "    [\n",
    "        (\n",
    "            'encoder', \n",
    "            OneHotEncoder(drop = None, handle_unknown='ignore'), \n",
    "            make_column_selector(dtype_include=[\"category\", \"object\"])\n",
    "        )\n",
    "    ], \n",
    "    remainder='passthrough', \n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776fc19b",
   "metadata": {},
   "source": [
    "### 4.2 Définir le _pipeline_\n",
    "\n",
    "On définit ensuite la seconde étape du traitement: le modèle de _machine learning_ proprement dit. En l'occurrence, il s'agit d'une forêt aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire la seconde étape du pipeline (la forêt aléatoire)\n",
    "rf_algorithm = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cfb18c",
   "metadata": {},
   "source": [
    "Une fois que les étapes de modélisation sont définies, on peut les rassembler explicitement dans un _pipeline_ pour constituer le modèle complet. C'est ce modèle que nous allons utiliser tout au long de ce tutoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b281ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le pipeline complet\n",
    "rf_model = Pipeline(\n",
    "    steps=[\n",
    "        # Étape 1: preprocessing\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        # Étape 2: le modèle de ML\n",
    "        (\"classifier\", rf_algorithm)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b484b181",
   "metadata": {},
   "source": [
    "### 4.3 Automatiser la construction du modèle\n",
    "Maintenant que nous avons vu comment construire un modèle complet sous forme de _pipeline_, nous allons automatiser cette tâche sous la forme d'une fonction. Cela permettra de générer un nouveau modèle à chaque fois que nous en aurons besoin. Ci-dessous, on définit la fonction `create_model()` qui reproduit le code présenté précédemment, et renvoie le modèle complet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bcb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(**params):\n",
    "    # One-hot-encoding des variables catégorielles\n",
    "    preprocessor  = ColumnTransformer( \n",
    "        [\n",
    "            (\n",
    "                'encoder', \n",
    "                OneHotEncoder(drop = None, handle_unknown='error'), \n",
    "                make_column_selector(dtype_include=[\"category\", \"object\"])\n",
    "            )\n",
    "        ], \n",
    "        remainder='passthrough', \n",
    "        verbose_feature_names_out=False,\n",
    "        sparse_threshold = 0\n",
    "    )\n",
    "\n",
    "    # Construire la seconde étape du pipeline (la forêt aléatoire)\n",
    "    rf_algorithm = RandomForestClassifier(**params)\n",
    "    \n",
    "    # Construire le pipeline complet\n",
    "    rf_model = Pipeline(\n",
    "        steps=[\n",
    "            # Etape 1: preprocessing\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            # Etape 2: le modèle de ML\n",
    "            (\"classifier\", rf_algorithm)\n",
    "        ]\n",
    "    )\n",
    "    return(rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## 5. Entraîner une première forêt aléatoire \n",
    "Dans cette section, nous allons entraîner une toute première forêt avec les __hyperparamètres par défaut__. Il est préférable d'avoir lu la [section](https://inseefrlab.github.io/DT_methodes_ensemblistes/chapters/chapter3/2-guide_usage_RF.html#sec-hyperparam-rf) du document de travail sur les hyperparamètres des forêts aléatoires avant de commencer cette partie.\n",
    "\n",
    "Il est important de noter que ces valeurs par défaut varie d'une implémentation à l'autre. Dans `scikit-learn`, [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) a les valeurs par défaut suivantes:\n",
    "\n",
    "|Hyperparamètre | Signification | Valeur par défaut |\n",
    "|:----:|----|:----:|\n",
    "| `n_estimators`           | Nombre d'arbres dans la forêt | 100 |\n",
    "| `max_features`           | Nombre de variables à considérer pour déterminer le meilleur _split_ | 'sqrt'|\n",
    "| `max_samples`            | La taille des échantillons aléatoires                                         | `n` |\n",
    "| `min_samples_leaf`       | Nombre minimum d'échantillons dans une feuille terminale | 1 |\n",
    "| `min_samples_split`      | Nombre minimal d'observations nécessaire pour qu'un noeud puisse être partagé | 2 |\n",
    "| `criterion`              | Le critère de choix de la règle de division des noeuds intermédiaires         | 'gini' |\n",
    "| `max_depth`              | Profondeur maximale des arbres                                                | None |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### 4.1 Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b3ec9",
   "metadata": {},
   "source": [
    "On commence par créer un modèle en faisant appel à la fonction `RandomForestClassifier()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a29beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle\n",
    "rf_default_settings = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "start_time = time.time()\n",
    "rf_default_settings.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Temps d'entraînement du modèle Random Forest : {elapsed_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb82e2",
   "metadata": {},
   "source": [
    "### 4.2 Représenter les arbres\n",
    "\n",
    "Le code ci-dessous permet de représenter un arbre. Attention, il est indispensable de spécifier `max_depth`, sinon le graphique sera ilisible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b574db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "# Plot the tree using the plot_tree function from sklearn\n",
    "tree = rf_default_settings[\"classifier\"].estimators_[0]\n",
    "plt.figure(figsize=(20,10))  # Set figure size to make the tree more readable\n",
    "plot_tree(tree, \n",
    "          filled=True,              # Fill nodes with colors for better visualization\n",
    "          rounded=True,\n",
    "          max_depth=2)             # Rounded edges for nodes\n",
    "plt.title(\"Decision Tree from the Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 4.3 Evaluation sur le jeu de test\n",
    "\n",
    "La matrice de confusion permet de visualiser les erreurs de classification.\n",
    "Le rapport de classification donne des métriques importantes comme la précision, le rappel et le F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred_baseline = rf_default_settings.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance avec une matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_baseline, labels=rf_default_settings.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=rf_default_settings.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion pour la prédiction de la détention du baccalauréat\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da08d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représenter la ROC curve\n",
    "RocCurveDisplay.from_estimator(model_default_settings, X_test, y_test, name=\"Model with default settings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## 5. Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd268d",
   "metadata": {},
   "source": [
    "Dans cette section, nous allons suivre pas à pas la procédure d'entraînement des forêts aléatoires détaillée [ici](https://inseefrlab.github.io/DT_methodes_ensemblistes/chapters/chapter3/2-guide_usage_RF.html). Nous allons donc aborder les étapes suivantes\n",
    "\n",
    "- Choisir le bon nombre d'arbres (`n_estimators`);\n",
    "- Explorer l'espaces des valeurs possibles pour min_samples_leaf avec un grid search (par validation croisée et par l'approche OOB);\n",
    "- Explorer l'espaces des valeurs possibles pour `max_features` (alias de `mtry`) et `max_samples` avec un _grid search_;\n",
    "- Evaluer l'apport de cette optimisation des hyperparamètres en comparant le modèle final à un modèle reposant sur les valeurs par défaut des hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### 5.1 Choisir le nombre d'arbres (`n_estimators`)\n",
    "\n",
    "Le nombre d'arbres d'une forêt aléatoire est un hyperparamètre particulier car il n'est associé à aucun arbitrage en matière de performance: la performance de la forêt aléatoire croît avec le nombre d'arbres, puis se stabilise à un niveau approximativement constant. Le nombre optimal d'arbres est donc intuitivement celui à partir duquel la performance de la forêt ne croît plus: il en faut \"assez\", mais pas \"trop\", d'autant qu'un nombre d'arbre élevé peut allonger considérablement le temps de calcul.\n",
    "\n",
    "La méthode proposée pour choisir le nombre d'arbre est la suivante:\n",
    "\n",
    "- on entraîne une forêt aléatoire avec les hyperparamètres par défaut, en augmentant progressivement le nombre d'arbres;\n",
    "- on calcule à chaque étape le taux d'erreur _out-of-bag_ du modèle en fonction du nombre d'arbres, en utilisant le [score de Brier](https://scikit-learn.org/dev/modules/model_evaluation.html#common-cases-predefined-values) comme métrique;\n",
    "- on représente graphiquement ce taux d'erreur en fonction du nombre d'arbres;\n",
    "- le nombre d'arbres optimal est celui à partir duquel le taux d'erreur ne diminue plus.\n",
    "\n",
    "Deux remarques sur cette approche:\n",
    "\n",
    "- Cette approche n'est pas parfaite, car le nombre optimal d'arbres dépend de la valeur des autres hyperparamètres, mais elle a le mérite d'être simple et rapide. \n",
    "- Il est possible d'appliquer cette approche avec une autre métrique que le score de Brier. La liste des métriques disponibles dans `scikit-learn` est [ici](https://scikit-learn.org/dev/modules/model_evaluation.html#common-cases-predefined-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ce code est inspiré de celui-ci: https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "\n",
    "# Créer un modèle avec les hyperparamètres par défaut\n",
    "# NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
    "# support for parallelized ensembles but is necessary for tracking the OOB\n",
    "# error trajectory during training.\n",
    "rf_nb_trees = RandomForestClassifier(\n",
    "    oob_score=brier_score_loss, # Ici il est possible de choisir une autre métrique pour calculer l'erreur OOB\n",
    "    warm_start=True,\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Préparer un dictionnaire pour stocker les résultats\n",
    "error_rate = dict()\n",
    "\n",
    "# Définir l'intervalle de valeurs à explorer\n",
    "min_estimators = 40\n",
    "max_estimators = 500\n",
    "increment_size = 20\n",
    "\n",
    "# Entraîner le modèle en augmentant le nombe d'arbres\n",
    "for n_trees in range(min_estimators, max_estimators + 1, increment_size):\n",
    "    print(n_trees)\n",
    "\n",
    "    # Définir le nombre d'arbres\n",
    "    rf_nb_trees.set_params(n_estimators=n_trees)\n",
    "    rf_nb_trees.fit(X_train, y_train)\n",
    "\n",
    "    # Conserver le taux d'erreur du modèle\n",
    "    error_rate[n_trees] = rf_nb_trees.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représenter graphiquement le taux d'erreur en fonction du nombre d'arbres\n",
    "x, y = zip(*sorted(error_rate.items()))\n",
    "plt.plot(x, y)\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"Nombre d'arbres\")\n",
    "plt.ylabel(f\"Taux d'erreur OOB (métrique = {rf_nb_trees.oob_score.__name__})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb742cc",
   "metadata": {},
   "source": [
    "On voit que la performance croît nettement avec le nombre d'arbres au début, puis se stabilise progressivement. La performance s'améliore peu au-delà de 200 arbres: on retient donc la valeur de 200 arbres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### 6.2 Choisir la taille de l'échantillon (`max_samples`) et la proportion de variables candidates (`max_features`)\n",
    "\n",
    "Nous allons maintenant choisir le taux d'échantillonnage et la proportion de variables candidates. Pour ce faire, nous allons explorer l'espace des valeurs possibles pour ces hyperparamètres, selon deux approches qui donnent généralement des résultats similaires (mais pas forcément identiques):\n",
    "\n",
    "- Une approche par validation croisée avec la fonction `GridSearchCV`;\n",
    "- Une approche par l'erreur OOB (_out-of-bag_).\n",
    "\n",
    "Deux points importants sont à noter:\n",
    "\n",
    "- l'approche par validation croisée est intense en calcul, mais est complètement standard et applicable à tous les algorithmes de machine learning supervisé. Inversement, __l'approche par l'ereur OOB est plus rapide, mais elle est exclusivement applicable aux forêts aléatoires__ et ne peut pas être utilisée avec d'autres algorithmes. Par ailleurs, elle est beaucoup moins bien (voire pas) documentée sur internet.\n",
    "- si vous testez un grand nombre de valeurs possibles pour les hyperparamètres par validation croisée, le temps de calcul peut devenir très long!\n",
    "\n",
    "Nous utilisons un modèle avec les hyperparamètres choisis jusqu'ici: `n_estimators = 200`. On rajoute également `min_samples_leaf = 10` car cela accélère l'entraînement, le plus souvent sans effet notable sur les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROCHE 1: Validation croisée\n",
    "\n",
    "# Créer un modèle avec 200 arbres\n",
    "model_grid_search = create_model(n_estimators = 200, min_samples_leaf = 10)\n",
    "\n",
    "# Créer un modèle avec 400 arbres, et tous les autres hyperparamètres par défaut\n",
    "rf_crossval = RandomForestClassifier(\n",
    "    n_estimators = 400,\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Définir la grille d'hyperparamètres\n",
    "param_grid = {\n",
    "    # Taille de l'échantillon\n",
    "    'classifier__max_samples': [0.6, 0.8, 1.0],\n",
    "    # Nombre de features candidates à chaque split \n",
    "    'max_features': ['sqrt', 0.6, 0.8, None] # None revient à faire du bagging\n",
    "}\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_crossval,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                         # Validation croisée à 5 plis\n",
    "    scoring='neg_brier_score',    # Métrique à optimiser\n",
    "    n_jobs=-1,                    # Utiliser tous les cœurs disponibles\n",
    "    verbose=1,                    # Afficher la progression\n",
    "    refit=True                    # Réentrainer le modèle avec les meilleurs paramètres\n",
    ")\n",
    "\n",
    "# Exécuter la recherche\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres\n",
    "print(\"Best parameters found:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROCHE 2: approche OOB\n",
    "# ATTENTION: cette approche est applicable exclusivement aux forêts aléatoires\n",
    "\n",
    "# Créer une variable pour conserver le score\n",
    "best_score = 0\n",
    "\n",
    "# Définir la grille d'hyperparamètres\n",
    "param_grid = {\n",
    "    # Taux d'échantillonnage\n",
    "    'max_samples': [0.6, 0.8, 1.0],\n",
    "    # Nombre de features candidates à chaque split \n",
    "    'max_features': ['sqrt', 'log2', None] # None revient à faire du bagging\n",
    "}\n",
    "\n",
    "# Entraîner le modèle et calculer l'erreur OOB avec la métrique choisie\n",
    "for g in ParameterGrid(param_grid):\n",
    "\n",
    "    # Créer un modèle avec 200 arbres\n",
    "    model_oob = create_model(\n",
    "        n_estimators=200, \n",
    "        min_samples_leaf=10,\n",
    "        oob_score=roc_auc_score, # Ici il est possible de choisir une autre métrique pour calculer l'erreur OOB\n",
    "        random_state=42, \n",
    "        n_jobs=-1,\n",
    "        **g\n",
    "    )\n",
    "    # Entraîner le modèle\n",
    "    model_oob.fit(X_train, y_train)\n",
    "    # Conserver le meilleur\n",
    "    if model_oob[\"classifier\"].oob_score_ > best_score:\n",
    "        best_score = model_oob[\"classifier\"].oob_score_\n",
    "        best_params = g\n",
    "        best_model_oob = copy.deepcopy(model_oob)\n",
    "        print(f\"{best_params}: {best_score}\")\n",
    "\n",
    "print(\"Meilleurs hyperparamètres:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd49e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer le meilleur modèle obtenu par l'approche Gridsearch sur les données de test\n",
    "best_model_gs = grid_search.best_estimator_\n",
    "y_pred_gs = best_model_gs.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer le meilleur modèle obtenu par l'approche OOB sur les données de test\n",
    "y_pred_oob = best_model_oob.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### 6.3 Influence de la taille minimale des feuilles (_min_samples_leaf_)\n",
    "\n",
    "Pour de faibles valeurs du nombre minimum d'observations par feuille (noeud terminal), le modèle risque de sur-ajuster les données d'entraînement; pour des valeurs élevées, le modèle devient plus simple, ce qui peut entraîner un sous-ajustement. Cet hyperparamètre n'est pas le plus important en termes de performance, mais il a une __influence majeure sur le temps d'entraînement du modèle__: une valeur faible implique des arbres profonds donc longs à entraîner. Il peut donc parfois être utile de vérifier assez tôt dans la procédure d'entraînement s'il est possible de le fixer à une valeur plus élevée que la valeur par défaut sans perte de performance, pour accélérer le reste de la procédure. Ceci dit, il faut garder en tête que la valeur optimale de cet hyperparamètre peut dépendre des autres hyperparamètres. \n",
    "\n",
    "Le code suivant montre comment on peut rapidement définir une valeur raisonnable pour cet hyperparamètre. Les résultats indiquent qu'une valeur de 10 est raisonnable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3dbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROCHE 1: Validation croisée\n",
    "\n",
    "# Créer un modèle avec 400 arbres, max_features = 0.6 et max_samples = 0.7\n",
    "rf_crossval_leaf_size = RandomForestClassifier(\n",
    "    n_estimators = 400,\n",
    "    max_features = 0.6,\n",
    "    max_samples = 0.5,\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Définir la grille d'hyperparamètres\n",
    "param_grid_leaf_size = {\n",
    "    # Taille minimale des feuilles\n",
    "    'min_samples_leaf': [1, 3, 5, 10, 20, 50, 100, 200, 500]\n",
    "}\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "grid_search_leaf_size = GridSearchCV(\n",
    "    estimator=rf_crossval_leaf_size,\n",
    "    param_grid=param_grid_leaf_size ,\n",
    "    cv=5,                         # Validation croisée à 5 plis\n",
    "    scoring='neg_brier_score',    # Métrique à optimiser\n",
    "    n_jobs=-1,                    # Utiliser tous les cœurs disponibles\n",
    "    verbose=1,                    # Afficher la progression\n",
    "    refit=True                    # Réentrainer le modèle avec les meilleurs paramètres\n",
    ")\n",
    "\n",
    "# Exécuter la recherche\n",
    "grid_search_leaf_size.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres\n",
    "print(\"Best parameters found:\", grid_search_leaf_size.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf88dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPROCHE 2: approche OOB\n",
    "# ATTENTION: cette approche est applicable exclusivement aux forêts aléatoires\n",
    "\n",
    "# Créer une variable pour conserver le score\n",
    "best_score_leaf_size = np.inf\n",
    "\n",
    "# Créer un modèle avec 400 arbres, max_features = 0.6 et max_samples = 0.7\n",
    "rf_oob_leaf_size = RandomForestClassifier(\n",
    "    n_estimators = 400,\n",
    "    max_features = 0.6,\n",
    "    max_samples = 0.5,\n",
    "    oob_score=brier_score_loss, # Ici il est possible de choisir une autre métrique pour calculer l'erreur OOB\n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Définir la grille d'hyperparamètres\n",
    "param_grid_leaf_size = {\n",
    "    # Taille minimale des feuilles\n",
    "    'min_samples_leaf': [1, 3, 5, 10, 20, 50, 100, 200, 500]\n",
    "}\n",
    "\n",
    "for g in ParameterGrid(param_grid_leaf_size):\n",
    "    print(g)\n",
    "    rf_oob_leaf_size.set_params(**g)\n",
    "    rf_oob_leaf_size.fit(X_train,y_train)\n",
    "    print(rf_oob_leaf_size.oob_score_)\n",
    "    # save if best\n",
    "    if rf_oob_leaf_size.oob_score_ < best_score:\n",
    "        best_score = rf_oob_leaf_size.oob_score_\n",
    "        best_params = g\n",
    "\n",
    "print(\"OOB: %0.5f\" % best_score) \n",
    "print(\"Best parameters found:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb64967",
   "metadata": {},
   "source": [
    "Les deux approches donnent à nouveau des résultats différents mais très proches: `min_samples_leaf = 5` et `min_samples_leaf = 3`,  soit des valeurs légèrement plus élevées que la valeur par défaut. On retient `min_samples_leaf = 5`. Le script suivant illustre l'influence de cet hyperparamètre sur la performance du modèle, mesurée par l'aire sous la courbe ROC. On voit bien qu'il y a un arbitrage entre des valeurs faibles (qui aboutissent à des arbres très profonds qui surajustent les données) et des valeurs élevées (qui aboutissent à des arbres trop simples et peu performants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafcc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Différentes valeurs de min_samples_leaf à tester\n",
    "min_samples_leaf_range = [5, 10, 15, 20, 30, 40, 50, 75, 100, 150, 200]\n",
    "scores = []\n",
    "\n",
    "for min_samples_leaf in min_samples_leaf_range:\n",
    "    t1 = time.time()\n",
    "\n",
    "    print(min_samples_leaf)\n",
    "\n",
    "    # Créer un modèle avec 200 arbres\n",
    "    model_oob = create_model(\n",
    "        n_estimators=200, \n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        oob_score=roc_auc_score,\n",
    "        random_state=42, \n",
    "        n_jobs=-1,\n",
    "        **g\n",
    "    )\n",
    "    # Entraîner le modèle\n",
    "    model_oob.fit(X_train,y_train)\n",
    "    t2 = time.time()\n",
    "    print(f'Training a model with min_samples_leaf={min_samples_leaf} took {t2-t1:3.1f} secondes.')\n",
    "\n",
    "    scores.append(model_oob[\"classifier\"].oob_score_)\n",
    "\n",
    "# Tracer les résultats\n",
    "plt.plot(min_samples_leaf_range, scores, marker='o')\n",
    "plt.xlabel('Valeurs de min_samples_leaf')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Influence de min_samples_leaf')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f327ab3",
   "metadata": {},
   "source": [
    "### 6.4 Entraîner le modèle final\n",
    "\n",
    "A l'issue des différentes étapes d'optimisation des hyperparamètres, nous arrivons au choix suivant:\n",
    "\n",
    "- `n_estimators = 200`;\n",
    "- `max_features = None`,\n",
    "- `max_samples = 10`;\n",
    "- `min_samples_leaf = 10`.\n",
    "\n",
    "On entraîne le modèle final avec ces hyperparamètres, et on affiche sa matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a73969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le modèle\n",
    "best_model = create_model(warm_start = True, oob_score = True)\n",
    "\n",
    "# Définir les hyperparamètres\n",
    "param_final = {\n",
    "    # Taille de l'échantillon\n",
    "    'classifier__n_estimators': 200,\n",
    "    # Nombre de features candidates à chaque split \n",
    "    'classifier__max_features': None,\n",
    "    # Taux d'échantillonnage des données\n",
    "    'classifier__max_samples': 0.6,\n",
    "    # Taille minimale des feuilles terminales\n",
    "    'classifier__min_samples_leaf': 10\n",
    "}\n",
    "\n",
    "# Passer les hyperparamètres au modèle\n",
    "best_model.set_params(\n",
    "    **param_final\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "best_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred_best = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance avec une matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_best, labels=best_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=best_model.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion pour la prédiction du niveau de diplôme\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc81490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représenter la ROC curve\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test, name=\"Best model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### 6.5 Comparaison avec le modèle de base\n",
    "On va maintenant comparer les performances du modèle final avec celles du  modèle entraîné avec les hyperparamètres par défaut. Le graphique ci-dessous compare les deux courbes ROC. On voit que le modèle final a des performances légèrement supérieures à celles du modèle de base. Cela illustre deux propriétés importantes des forêts aléatoires: __elles sont relativement peu sensibles aux valeurs des hyperparamètres, et un modèle entraîné avec les valeurs par défaut présente généralement des performances satisfaisantes.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b0f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()  # get current axes\n",
    "\n",
    "# Plot ROC curve for the first random forest\n",
    "rfc_disp1 = RocCurveDisplay.from_estimator(model_default_settings, X_test, y_test, ax=ax, curve_kwargs={\"alpha\": 0.8}, name=\"Model with default settings\")\n",
    "\n",
    "# Plot ROC curve for the second random forest on the same plot\n",
    "rfc_disp2 = RocCurveDisplay.from_estimator(best_model, X_test, y_test, ax=ax, curve_kwargs={\"alpha\": 0.8}, name=\"Best model\")\n",
    "\n",
    "plt.title(\"Comparaison des deux modèles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## 7. Interprétation du modèle : Importance des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### 7.1 Extraire l'importance des variables\n",
    "L'importance des variables reflète leur contribution à la qualité des prédictions du modèle. Parmi les différentes mesures disponibles, nous utilisons ici la \"Mean Decrease in Impurity\" (MDI). Cette métrique évalue la contribution de chaque variable à la réduction de l'impureté moyenne dans l'arbre de décision. \n",
    "Pour chaque variable, elle correspond à la moyenne des réductions d’impureté (par exemple, l'indice de Gini ou l'entropie) qu’elle a engendrées dans tous les nœuds de tous les arbres où elle est impliquée. Les variables présentant la réduction moyenne d’impureté la plus élevée sont considérées comme les prédicteurs les plus importants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des variables (Mean Decrease in Impurity)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Variable_modele': best_model[\"preprocessor\"].get_feature_names_out(),\n",
    "    'Importance': best_model[\"classifier\"].feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1992db",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1c41a",
   "metadata": {},
   "source": [
    "Si on affiche la table d'importance, on constate tout de suite une difficulté: l'importance des variables catégorielles qui ont fait l'objet d'un _one-hot-encoding_ est répartie sur plusieurs lignes (une par variable issue du _one-hot-encoding_). Il faut donc réagréger les mesures d'importance pour obtenir des données plus interprétables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ae0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire un dictionnaire qui associe nom de variables et éléments de la table d'importance\n",
    "dict_ohe = {}\n",
    "for i in range(len(best_model[\"preprocessor\"][\"encoder\"].feature_names_in_.tolist())):\n",
    "    dict_ohe[best_model[\"preprocessor\"][\"encoder\"].feature_names_in_.tolist()[i]] =  [\n",
    "        best_model[\"preprocessor\"][\"encoder\"].feature_names_in_.tolist()[i] + '_' + z \n",
    "        for z in best_model[\"preprocessor\"][\"encoder\"].categories_[i].tolist()\n",
    "    ]\n",
    "\n",
    "dict_ohe = {v: k for k, values in dict_ohe.items() for v in values}\n",
    "\n",
    "dict_remainder = {}\n",
    "for i in range(len(best_model[\"preprocessor\"][\"remainder\"].feature_names_in_.tolist())):\n",
    "    dict_remainder[best_model[\"preprocessor\"][\"remainder\"].feature_names_in_.tolist()[i]] =  best_model[\"preprocessor\"][\"remainder\"].feature_names_in_.tolist()[i]\n",
    "\n",
    "dict_labels = merged = {**dict_ohe, **dict_remainder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df[\"Variable\"] = importance_df[\"Variable_modele\"].map(dict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les noms des colonnes\n",
    "feature_names = X_train.columns\n",
    "raw_feature_names = data_sample.drop(\"bac\", axis = 1).columns\n",
    "\n",
    "# Appeler la fonction pour regrouper les importances\n",
    "aggregated_importance_df = importance_df.groupby(\"Variable\")[\"Importance\"].sum().reset_index()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(aggregated_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b780e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les libellés des variables depuis le dictionnaire\n",
    "doc_census_individuals_noms_variables = doc_census_individuals[['COD_VAR', 'LIB_VAR']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associer les libellés (descriptions) aux variables d'importance\n",
    "importance_df_with_labels = aggregated_importance_df.merge(\n",
    "    doc_census_individuals_noms_variables,\n",
    "    left_on='Variable',\n",
    "    right_on='COD_VAR',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### 7.2 Visualisation des variables les plus importantes\n",
    "La visualisation aide à comprendre quelles variables contribuent le plus à la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour visualiser les n variables les plus importantes\n",
    "def plot_top_n_variables(importance_df, variable_col='Variable', importance_col='Importance', top_n=10):\n",
    "    \"\"\"\n",
    "    Visualise les n variables les plus importantes à partir d'un DataFrame d'importance.\n",
    "\n",
    "    Parameters:\n",
    "    - importance_df (pd.DataFrame): Un DataFrame contenant les colonnes spécifiées.\n",
    "    - variable_col (str): Le nom de la colonne contenant les noms des variables.\n",
    "    - importance_col (str): Le nom de la colonne contenant les valeurs d'importance.\n",
    "    - top_n (int): Le nombre de variables les plus importantes à afficher.\n",
    "    \"\"\"\n",
    "    # Vérifier si les colonnes existent\n",
    "    if variable_col not in importance_df.columns or importance_col not in importance_df.columns:\n",
    "        raise ValueError(f\"Les colonnes '{variable_col}' et/ou '{importance_col}' ne sont pas présentes dans le DataFrame.\")\n",
    "\n",
    "    # Trier par importance décroissante\n",
    "    top_variables = importance_df.sort_values(by=importance_col, ascending=False).head(top_n)\n",
    "\n",
    "    # Création du graphique\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(top_variables[variable_col], top_variables[importance_col], color='steelblue')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Variable\")\n",
    "    plt.title(f\"Top {top_n} variables les plus importantes\")\n",
    "    plt.gca().invert_yaxis()  # Afficher les plus importantes en haut\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des variables les plus importantes\n",
    "plot_top_n_variables(\n",
    "    importance_df = importance_df_with_labels,\n",
    "    variable_col='LIB_VAR',\n",
    "    importance_col='Importance',\n",
    "    top_n=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde13621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61dd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126c6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a4c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a625f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
