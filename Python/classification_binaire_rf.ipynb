{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Classification binaire: prédire la détention du baccalauréat dans le recensement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Présentation\n",
    "Dans ce tutoriel, nous allons voir comment utiliser une forêt aléatoire en Python avec l'implémentation de `scikit-learn`. Cet algorithme est présenté en détail dans le document de travail ([ici](https://inseefrlab.github.io/DT_methodes_ensemblistes/chapters/chapter2/3-random_forest.html)).\n",
    "\n",
    "Ce tutoriel se concentre donc sur la mise en oeuvre pratique de l'algorithme. Nous présentons les étapes suivantes: la préparation des données, la construction du modèle, l'entraînement du modèle, l'optimisation des hyperparamètres et quelques éléments d'interprétation des résultats.\n",
    "\n",
    "Le jeu de données est issu du recensement de la population (Insee) et contient des informations individuelles issues du recensement, telles que l'âge, le niveau d'éducation, la situation professionnelle, etc. L'objectif sera de prédire si un individu a obtenu le baccalauréat en fonction de ses autres caractéristiques observées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 2. Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 2.1 Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques pour la manipulation des données\n",
    "import os\n",
    "import s3fs\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Bibliothèques pour la visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliothèques pour le traitement des données\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Bibliothèques pour le modèle et l'évaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay, \n",
    "    roc_curve,\n",
    "    RocCurveDisplay,\n",
    "    brier_score_loss,\n",
    "    log_loss,\n",
    "    roc_auc_score\n",
    "\n",
    "# Pour mesurer le temps d'exécution\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.2 Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la liste des variables à conserver\n",
    "variable_list = [\n",
    "    'AGED', 'APAF', 'CATL', 'CATPC', 'COUPLE', 'CS1', 'DEPT', 'DIPL', \n",
    "    'EMPL', 'HLML', 'ILETUD', 'ILT', 'IMMI', 'INAI', 'INATC', 'INFAM', \n",
    "    'INPER', 'INPERF', 'IRAN', 'LIENF', 'LPRF', 'LPRM', 'METRODOM', 'MOCO',\n",
    "     'MODV', 'NA17', 'NA5', 'NAIDT', 'NBPI', 'NENFR', 'NPERR', 'ORIDT', 'SEXE', \n",
    "     'SFM', 'STAT_CONJ', 'STATR', 'STOCD', 'SURF', 'TACTD16', \n",
    "     'TP', 'TRANS', 'TYPC', 'TYPFC'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ba890-9842-4500-871e-3d03be6f4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se connecter au bucket\n",
    "endpoint = \"https://\"+os.environ['AWS_S3_ENDPOINT']\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': endpoint}, anon=True)\n",
    "\n",
    "# Charger les données individuelles  du recensement\n",
    "with fs.open('s3://oliviermeslin/rp/data_census_individuals.parquet', 'rb') as file:\n",
    "    data_census_individuals = pd.read_parquet(file, columns = variable_list)\n",
    "\n",
    "# Charger la documentation\n",
    "# doc_census_individuals = read_csv_data(\"documentation/doc_census_individuals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les premières lignes du jeu de données\n",
    "data_census_individuals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 3. Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 3.1 Echantillonnage des données\n",
    "Compte tenu de l'objectif pédagogique de ce tutoriel, nous tirons un échantillon aléatoire de taille restreinte (0,5 % des observations), représentatif de l'ensemble des données initiales, afin d'accélérer les calculs dans les sections suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Échantillonner les données (1/200)\n",
    "data_sample = data_census_individuals.sample(frac=1/200, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### 3.2 Création de la variable cible\n",
    "\n",
    "Nous créons la variable que l'on va tâcher de prédire: une variable indicatrice qui vaut 1 pour les individus détenteurs du baccalauréat, 0 pour les autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e46bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir la répartition des classes de diplôme\n",
    "print(data_sample['DIPL'].isna().sum())  # Vérification des valeurs manquantes\n",
    "print(data_sample['DIPL'].value_counts())  # Distribution des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préciser l'odre des catégories de DIPL (ZZ suivi des valeurs numériques croissantes)\n",
    "categories = ['ZZ'] + [f\"{i:02}\" for i in range(1, 20)]\n",
    "data_sample['DIPL'] = pd.Categorical(data_sample['DIPL'], categories=categories, ordered=True)\n",
    "\n",
    "# Créer la variable binaire 'bac'\n",
    "data_sample['bac'] = (data_sample['DIPL'] > '13').astype(int)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(data_sample[['DIPL', 'bac']].head(20))\n",
    "print(data_sample['bac'].value_counts())  # Distribution des classes\n",
    "\n",
    "# Supprimer la colonne 'DIPL' du DataFrame (car c'est un prédicteur parfait du baccalauréat)\n",
    "data_sample = data_sample.drop(columns=['DIPL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 3.3 Préparation des variables explicatives (_features_)\n",
    "Dans un premier temps, on transforme en variables continues toutes les variables catégorielles qui peuvent l'être. Certaines variables catégorielles comportent un ordre naturel, mais comprennent également une modalité \"X\" ou \"Z\" correspondant à une valeur manquante (ou non pertinente). Nous remplaçons cette modalité par une valeur numérique extrême (99 ou 999), ce qui permet de convertir la variable en variable continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dupliquer la table de données avant de retraiter les features\n",
    "data_clean = copy.deepcopy(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une fonction qui teste si une chaîne de caractères peut être convertie en un entier\n",
    "def can_convert_to_int(value):\n",
    "    try:\n",
    "        int(value)  # Attempt to convert the value to an integer\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c585455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer en variables continues toutes les variables qui peuvent l'être\n",
    "for var in data_clean.columns.tolist():\n",
    "    if data_clean[var].dtype.name == \"category\":\n",
    "        if set([category for category in data_clean[var].cat.categories if not can_convert_to_int(category)]) <= set(['X', 'Z']):\n",
    "            data_clean[var] = data_clean[var].cat.rename_categories({'X': '99', 'Z': '999'})\n",
    "            data_clean[var] = data_clean[var].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c409e",
   "metadata": {},
   "source": [
    "On sépare enfin les _features_ et la variable-cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les features (X) et la variable cible (y : bac)\n",
    "X = data_clean.drop(columns=['bac'])\n",
    "y = data_clean['bac']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### 3.4 Séparation des ensembles d'entraînement et de test\n",
    "On utilise la fonction [`train_test_split()`](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html) pour séparer l'ensemble d'entraînement et l'ensemble de test. La stratification en fonction de $y$ assure que la proportion des classes est la même dans les ensembles d'entraînement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement (80%) et de test (20%) avec stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e936df",
   "metadata": {},
   "source": [
    "## 4. Construire le modèle complet\n",
    "\n",
    "Nous allons construire le modèle complet en utilisant __un _pipeline_ `scikit-learn`, dont l'usage est très fortement recommandé__. Ce _pipeline_ va comprendre deux étapes: le _preprocessing_ des données, puis la forêt aléatoire proprement dite.\n",
    "\n",
    "Un _pipeline_ `scikit-learn` est un objet informatique qui permet d'assurer une exécution cohérente de plusieurs étapes de traitement des données. Par exemple, un _pipeline_ permet de réaliser la normalisation des variables, le traitement des valeurs manquantes, l'encodage des variables catégorielles, et l'entraînement d'un modèle __en une seule étape__. Utiliser un _pipeline_ simplifie les codes et garantit que les mêmes transformations sont appliquées aux données d'entraînement et de test, ce qui réduit le risque d'erreur et augmente la reproductibilité des résultats. Si vous n'êtes pas habitué à les utiliser, il est fortement recommandé de lire la [documentation officielle sur ce sujet](https://scikit-learn.org/1.5/modules/compose.html) et l'[excellente formation](https://pythonds.linogaliana.fr/content/modelisation/6_pipeline.html) de Lino Galiana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b5b69",
   "metadata": {},
   "source": [
    "### 4.1 Le préprocessing des données\n",
    "Le _préprocessing_ des données est construit avec la fonction  [`ColumnTransformer()`](https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html) de `scikit` et n'est pas le même selon le type des variables:\n",
    "- on applique un _one-hot-encoding_ aux variables catégorielles, avec la fonction [`OneHotEncoder()`](https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OneHotEncoder.html) de `scikit`. On choisit d'encoder toutes les modalités (`drop=None`). L'option `handle_unknown='error'` signifie que le modèle renverra une erreur s'il rencontre une modalité inconnue lors de l'utilisation en prédiction.\n",
    "- On applique aucune transformation aux variables numériques car les méthodes ensemblistes sont invariantes aux transformations monotones des _features_. On utilise donc l'option \"passthrough\".\n",
    "\n",
    "On utilise la fonction [`make_column_selector()`](https://scikit-learn.org/1.5/modules/generated/sklearn.compose.make_column_selector.html) permet d'appliquer le bon _preprocessing_ en fonction du type des variables, sans avoir à en faire une liste explicite.\n",
    "\n",
    "Pour plus d'explications, vous pouvez lire la partie du document de travail sur la [préparation des données](https://inseefrlab.github.io/DT_methodes_ensemblistes/chapters/chapter3/1-preparation_donnees.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire la première étape du pipeline (préprocessing des données)\n",
    "\n",
    "# One-hot-encoding des variables catégorielles\n",
    "preprocessor  = ColumnTransformer( \n",
    "    [\n",
    "        (\n",
    "            'encoder', \n",
    "            OneHotEncoder(drop = None, handle_unknown='error'), \n",
    "            make_column_selector(dtype_include=[\"category\", \"object\"])\n",
    "        )\n",
    "    ], \n",
    "    remainder='passthrough', \n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776fc19b",
   "metadata": {},
   "source": [
    "### 4.2 Définir le _pipeline_\n",
    "\n",
    "On définit ensuite la seconde étape du traitement: le modèle de _machine learning_ proprement dit. En l'occurrence, il s'agit d'une forêt aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire la seconde étape du pipeline (la forêt aléatoire)\n",
    "rf_algorithm = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cfb18c",
   "metadata": {},
   "source": [
    "Une fois que les étapes de modélisation sont définies, on peut les rassembler explicitement dans un _pipeline_ pour constituer le modèle complet. C'est ce modèle que nous allons utiliser tout au long de ce tutoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b281ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le pipeline complet\n",
    "rf_model = Pipeline(\n",
    "    steps=[\n",
    "        # Étape 1: preprocessing\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        # Étape 2: le modèle de ML\n",
    "        (\"classifier\", rf_algorithm)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b484b181",
   "metadata": {},
   "source": [
    "### 4.3 Automatiser la construction du modèle\n",
    "Maintenant que nous avons vu comment construire un modèle complet sous forme de _pipeline_, nous allons automatiser cette tâche sous la forme d'une fonction. Cela permettra de générer un nouveau modèle à chaque fois que nous en aurons besoin. Ci-dessous, on définit la fonction `create_model()` qui reproduit le code présenté précédemment, et renvoie le modèle complet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bcb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(**params):\n",
    "    # One-hot-encoding des variables catégorielles\n",
    "    preprocessor  = ColumnTransformer( \n",
    "        [\n",
    "            (\n",
    "                'encoder', \n",
    "                OneHotEncoder(drop = None, handle_unknown='error'), \n",
    "                make_column_selector(dtype_include=[\"category\", \"object\"])\n",
    "            )\n",
    "        ], \n",
    "        remainder='passthrough', \n",
    "        verbose_feature_names_out=False,\n",
    "        sparse_threshold = 0\n",
    "    )\n",
    "\n",
    "    # Construire la seconde étape du pipeline (la forêt aléatoire)\n",
    "    rf_algorithm = RandomForestClassifier(n_jobs=-1, **params)\n",
    "    \n",
    "    # Construire le pipeline complet\n",
    "    rf_model = Pipeline(\n",
    "        steps=[\n",
    "            # Etape 1: preprocessing\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            # Etape 2: le modèle de ML\n",
    "            (\"classifier\", rf_algorithm)\n",
    "        ]\n",
    "    )\n",
    "    return(rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## 5. Entraîner une première forêt aléatoire \n",
    "Dans cette section, nous allons entraîner une toute première forêt avec les __hyperparamètres par défaut__. Il est préférable d'avoir lu la [section](https://inseefrlab.github.io/DT_methodes_ensemblistes/chapters/chapter3/2-guide_usage_RF.html#sec-hyperparam-rf) du document de travail sur les hyperparamètres des forêts aléatoires avant de commencer cette partie.\n",
    "\n",
    "Il est important de noter que ces valeurs par défaut varie d'une implémentation à l'autre. Dans `scikit-learn`, [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) a les valeurs par défaut suivantes:\n",
    "\n",
    "|Hyperparamètre | Signification | Valeur par défaut |\n",
    "|:----:|----|:----:|\n",
    "| `n_estimators`           | Nombre d'arbres dans la forêt | 100 |\n",
    "| `max_features`           | Nombre de variables à considérer pour déterminer le meilleur _split_ | 'sqrt'|\n",
    "| `max_samples`            | La taille des échantillons aléatoires                                         | `n` |\n",
    "| `min_samples_leaf`       | Nombre minimum d'échantillons dans une feuille terminale | 1 |\n",
    "| `min_samples_split`      | Nombre minimal d'observations nécessaire pour qu'un noeud puisse être partagé | 2 |\n",
    "| `criterion`              | Le critère de choix de la règle de division des noeuds intermédiaires         | 'gini' |\n",
    "| `max_depth`              | Profondeur maximale des arbres                                                | None |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### 5.1 Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b3ec9",
   "metadata": {},
   "source": [
    "On commence par créer un modèle grâce à la fonction `create_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a29beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle\n",
    "model_default_settings = create_model(random_state=42, oob_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "start_time = time.time()\n",
    "model_default_settings.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Temps d'exécution du modèle Random Forest : {elapsed_time:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 5.2 Evaluation sur le jeu de test\n",
    "\n",
    "La matrice de confusion permet de visualiser les erreurs de classification.\n",
    "Le rapport de classification donne des métriques importantes comme la précision, le rappel et le F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred = model_default_settings.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance avec une matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=model_default_settings[\"classifier\"].classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=model_default_settings[\"classifier\"].classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion pour la prédiction de la détention du baccalauréat\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da08d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représenter la ROC curve\n",
    "RocCurveDisplay.from_estimator(model_default_settings, X_test, y_test, name=\"Model 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## 6. Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd268d",
   "metadata": {},
   "source": [
    "Dans cette section, nous allons suivre pas à pas le guide d'entraînement des forêts aléatoires détaillé ici. Nous allons donc aborder les étapes suivantes:\n",
    "\n",
    "- Choisir le bon nombre d'arbres (`n_estimators`);\n",
    "- Explorer l'espaces des valeurs possibles pour `max_features` (alias de `mtry`) et `max_samples` avec un _grid search_;\n",
    "- Explorer l'espaces des valeurs possibles pour `param3` et `param4` avec un _grid search_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### 6.1 Choisir le nombre d'arbres (`n_estimators`)\n",
    "\n",
    "Le nombre d'arbres d'une forêt aléatoire est un hyperparamètre particulier car il n'est associé à aucun arbitrage en matière de performance: la performance de la forêt aléatoire croît avec le nombre d'arbres, puis se stabilise à un niveau approximativement constant. Le nombre optimal d'arbres est donc intuitivement celui à partir duquel la performance de la forêt ne croît plus: il en faut \"assez\", mais pas \"trop\", d'autant qu'un nombre d'arbre élevé peut allonger considérablement le temps de calcul.\n",
    "\n",
    "La méthode proposée pour choisir le nombre d'arbre est la suivante:\n",
    "\n",
    "- on entraîne une forêt aléatoire avec les hyperparamètres par défaut, en augmentant progressivement le nombre d'arbres;\n",
    "- on calcule à chaque étape le taux d'erreur _out-of-bag_ du modèle en fonction du nombre d'arbres;\n",
    "- on représente graphiquement ce taux d'erreur en fonction du nombre d'arbres;\n",
    "- le nombre d'arbres optimal est celui à partir duquel le taux d'erreur ne diminue plus.\n",
    "\n",
    "Deux remarques sur cette approche:\n",
    "\n",
    "- Cette approche n'est pas parfaite, car le nombre optimal d'arbres dépend de la valeur des autres hyperparamètres, mais elle a le mérite d'être simple et rapide. \n",
    "- Il est possible d'appliquer cette approche avec une autre métrique que le taux d'erreur _out-of-bag_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ce code est inspiré de celui-ci: https://scikit-learn.org/stable/auto_examples/ensemble/plot_ensemble_oob.html\n",
    "\n",
    "# Créer un modèle\n",
    "# NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
    "# support for parallelized ensembles but is necessary for tracking the OOB\n",
    "# error trajectory during training.\n",
    "model = create_model(warm_start = True, oob_score = True)\n",
    "\n",
    "# Préparer un dictionnaire pour stocker les résultats\n",
    "error_rate = dict()\n",
    "\n",
    "# Définir l'intervalle de valeurs à explorer\n",
    "min_estimators = 20\n",
    "max_estimators = 500\n",
    "increment_size = 20\n",
    "\n",
    "# Entraîner le modèle en augmentant le nombe d'arbres\n",
    "for n_trees in range(min_estimators, max_estimators + 1, increment_size):\n",
    "    print(n_trees)\n",
    "\n",
    "    # Définir le nombre d'arbres\n",
    "    model[\"classifier\"].set_params(n_estimators=n_trees)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Conserver le taux d'erreur du modèle\n",
    "    oob_error = 1 - model[\"classifier\"].oob_score_\n",
    "    error_rate[n_trees] = oob_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représenter graphiquement le taux d'erreur en fonction du nombre d'arbres\n",
    "x, y = zip(*sorted(error_rate.items()))\n",
    "plt.plot(x, y)\n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"Nombre d'arbres\")\n",
    "plt.ylabel(\"Taux d'erreur OOB\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb742cc",
   "metadata": {},
   "source": [
    "On voit que la performance croît nettement avec le nombre d'arbres au début, puis se stabilise progressivement. La performance s'améliore peu au-delà de 400 arbres: on retient donc la valeur de 400 arbres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### 6.2 Choisir la taille de l'échantillon (`max_samples`) et la proportion de variables candidates (`max_features`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle avec 400 arbres\n",
    "model_grid_search = create_model(n_estimators = 400, min_samples_leaf = 10)\n",
    "\n",
    "# La taille de l'échantillon\n",
    "n = X_train.shape[0]\n",
    "\n",
    "# Définir la grille d'hyperparamètres\n",
    "param_grid = {\n",
    "    # Taille de l'échantillon\n",
    "    'classifier__max_samples': [round(0.6 * n), round(0.8 * n), n],\n",
    "    # Nombre de features candidates à chaque split \n",
    "    'classifier__max_features': ['sqrt', 'log2', None] # None revient à faire du bagging\n",
    "}\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_grid_search,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                 # Validation croisée à 3 plis\n",
    "    scoring='roc_auc',    # Métrique à optimiser\n",
    "    n_jobs=-1,            # Utiliser tous les cœurs disponibles\n",
    "    verbose=3             # Afficher la progression\n",
    ")\n",
    "\n",
    "# Exécuter la recherche\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs hyperparamètres\n",
    "print(\"Best parameters found:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd49e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer le meilleur modèle sur les données de test\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features_options = ['sqrt', 0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.8, None]\n",
    "scores = []\n",
    "d = X_train.shape[1]  # Nombre total de caractéristiques dans le jeu de données\n",
    "\n",
    "# Stocker les résultats pour le tri lors de la visualisation\n",
    "results = []\n",
    "\n",
    "for mf in max_features_options:\n",
    "\n",
    "    print(f\"Entraînement en cours avec max_features = {mf} ({num_features} features)\")  # Affichage de la valeur actuelle\n",
    "\n",
    "    # Calculer le nombre de features sélectionnés pour chaque option\n",
    "    if isinstance(mf, float):  # Si mf est une fraction\n",
    "        num_features = int(mf * d)\n",
    "    elif mf == 'sqrt':  # Si mf est 'sqrt'\n",
    "        num_features = int(np.sqrt(d))\n",
    "    elif mf == 'log2':  # Si mf est 'log2'\n",
    "        num_features = int(np.log2(d))\n",
    "    elif mf is None:  # Si mf est None\n",
    "        num_features = d\n",
    "    else:\n",
    "        num_features = None\n",
    "\n",
    "    # Entraîner et évaluer le modèle\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_features=mf,\n",
    "        min_samples_leaf=100,\n",
    "        random_state=123,\n",
    "        n_jobs=-1  # Parallélise la construction des arbres\n",
    "    )\n",
    "    score = cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "    # Ajouter les résultats pour tri ultérieur\n",
    "    results.append((mf, num_features, score))\n",
    "\n",
    "# Trier les résultats par ordre croissant du nombre de features\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "# Extraire les labels et scores triés\n",
    "labels = [f\"{mf} ({num_features})\" for mf, num_features, _ in results]\n",
    "scores = [score for _, _, score in results]\n",
    "\n",
    "# Visualisation\n",
    "plt.plot(labels, scores, marker='o')\n",
    "plt.xlabel('max_features (nombre de features)')\n",
    "plt.ylabel('Accuracy moyenne (validation croisée)')\n",
    "plt.title('Influence de max_features')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)  # Incliner les labels pour une meilleure lisibilité\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## Influence de la taille minimale des feuilles (min_samples_leaf)\n",
    "\n",
    "Pour de faibles valeurs du nombre minimum d'observations par feuille (noeud terminal), le modèle risque de sur-ajuster les données d'entraînement; pour des valeurs élevées, le modèle devient plus simple, ce qui peut entraîner un sous-ajustement.\n",
    "\n",
    "L'objectif est donc de trouver un compromis optimal entre ces deux situations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Différentes valeurs de min_samples_leaf à tester\n",
    "min_samples_leaf_range = [5, 10, 50, 100, 500]\n",
    "scores = []\n",
    "\n",
    "for min_samples_leaf in min_samples_leaf_range:\n",
    "        \n",
    "    print(f\"Entraînement en cours avec min_samples_leaf = {min_samples_leaf}\")  # Affichage de la valeur actuelle\n",
    "\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=300,  # Fixé à 500 arbres\n",
    "        max_features='sqrt',\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=123\n",
    "    )\n",
    "    score = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "# Tracer les résultats\n",
    "plt.plot(min_samples_leaf_range, scores, marker='o')\n",
    "plt.xlabel('Valeurs de min_samples_leaf')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Influence de min_samples_leaf')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## Recherche de la meilleure combinaison d'hyperparamètres: Grid Search pour optimiser plusieurs hyperparamètres à la fois\n",
    "\n",
    "GridSearchCV de scikit-learn permet d'optimiser de manière simultanée plusieurs hyperparamètres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### Définition de la grille de paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_leaf': [1, 10, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Mise en place de la Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=123),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Exécution du Grid Search\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Résultats de la Grid Search : identification du modèle le plus performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meilleurs paramètres :\", grid_search.best_params_)\n",
    "print(\"Meilleure précision :\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "# 6. Evaluer la performance du modèle optimisé par Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Prédictions et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Précision sur le jeu de test :\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance avec une matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=best_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=best_model.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion pour la prédiction du niveau de diplôme\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## Comparaison avec le modèle initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'accuracy sur le jeu de test pour les deux modèles\n",
    "initial_accuracy = rf_model.score(X_test, y_test)\n",
    "optimized_accuracy = best_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Accuracy du modèle initial : {initial_accuracy:.4f}\")\n",
    "print(f\"Accuracy du modèle optimisé : {optimized_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f902012",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "for (model, c, name) in zip(\n",
    "    (model1, model1),\n",
    "     ('r', 'b'),\n",
    "     ('Model 1',\n",
    "      'Model 2')\n",
    "    ):\n",
    "    RocCurveDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        name=name,\n",
    "        ax=ax,\n",
    "        color=c\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "# 7. Interprétation du modèle : Importance des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## Extraction de l'importance des variables: leur contribution à la performance du modèle\n",
    "L'importance des variables reflète leur contribution à la qualité des prédictions du modèle. Parmi les différentes mesures disponibles, nous utilisons ici la \"Mean Decrease in Impurity\" (MDI). Cette métrique évalue la contribution de chaque variable à la réduction de l'impureté moyenne dans l'arbre de décision. \n",
    "Pour chaque variable, elle correspond à la moyenne des réductions d’impureté (par exemple, l'indice de Gini ou l'entropie) qu’elle a engendrées dans tous les nœuds de tous les arbres où elle est impliquée. Les variables présentant la réduction moyenne d’impureté la plus élevée sont considérées comme les prédicteurs les plus importants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des variables (Mean Decrease in Impurity)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "## Agrégation des importances pour les variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rassembler l'importance des modalités d'une même variable\n",
    "def calculate_aggregated_importance(X, feature_importances):\n",
    "    \"\"\"\n",
    "    Agrège l'importance des variables catégorielles encodées en colonnes multiples.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Les données d'entraînement (features).\n",
    "        feature_importances (array): Les importances des variables calculées par le modèle.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Importance des variables agrégées par nom de variable.\n",
    "    \"\"\"\n",
    "    # Récupérer les noms des colonnes\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Initialiser un dictionnaire pour stocker les importances agrégées\n",
    "    aggregated_importance = {}\n",
    "\n",
    "    for col in feature_names:\n",
    "        # Identifier les variables spécifiques pour regrouper correctement\n",
    "        if col.startswith('STAT_CONJ_'):\n",
    "            variable = 'STAT_CONJ'\n",
    "        elif col.startswith('STATR_'):\n",
    "            variable = 'STATR'\n",
    "        else:\n",
    "            # Utiliser le préfixe par défaut basé sur le premier segment avant \"_\"\n",
    "            variable = col.split('_')[0]\n",
    "        \n",
    "        # Additionner les importances pour chaque variable \"parent\"\n",
    "        if variable in aggregated_importance:\n",
    "            aggregated_importance[variable] += feature_importances[feature_names.get_loc(col)]\n",
    "        else:\n",
    "            aggregated_importance[variable] = feature_importances[feature_names.get_loc(col)]\n",
    "\n",
    "    # Convertir en DataFrame trié par importance\n",
    "    aggregated_df = pd.DataFrame({\n",
    "        'Variable': aggregated_importance.keys(),\n",
    "        'Importance': aggregated_importance.values()\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appeler la fonction pour regrouper les importances\n",
    "aggregated_importance_df = calculate_aggregated_importance(X, best_model.feature_importances_)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(aggregated_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les libellés des variables depuis le dictionnaire\n",
    "doc_census_individuals_noms_variables = doc_census_individuals[['COD_VAR', 'LIB_VAR']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associer les libellés (descriptions) aux variables d'importance\n",
    "importance_df_with_labels = aggregated_importance_df.merge(\n",
    "    doc_census_individuals_noms_variables,\n",
    "    left_on='Variable',\n",
    "    right_on='COD_VAR',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "## Visualisation des variables les plus importantes\n",
    "La visualisation aide à comprendre quelles variables contribuent le plus à la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour visualiser les n variables les plus importantes\n",
    "def plot_top_n_variables(importance_df, variable_col='Variable', importance_col='Importance', top_n=10):\n",
    "    \"\"\"\n",
    "    Visualise les n variables les plus importantes à partir d'un DataFrame d'importance.\n",
    "\n",
    "    Parameters:\n",
    "    - importance_df (pd.DataFrame): Un DataFrame contenant les colonnes spécifiées.\n",
    "    - variable_col (str): Le nom de la colonne contenant les noms des variables.\n",
    "    - importance_col (str): Le nom de la colonne contenant les valeurs d'importance.\n",
    "    - top_n (int): Le nombre de variables les plus importantes à afficher.\n",
    "    \"\"\"\n",
    "    # Vérifier si les colonnes existent\n",
    "    if variable_col not in importance_df.columns or importance_col not in importance_df.columns:\n",
    "        raise ValueError(f\"Les colonnes '{variable_col}' et/ou '{importance_col}' ne sont pas présentes dans le DataFrame.\")\n",
    "\n",
    "    # Trier par importance décroissante\n",
    "    top_variables = importance_df.sort_values(by=importance_col, ascending=False).head(top_n)\n",
    "\n",
    "    # Création du graphique\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(top_variables[variable_col], top_variables[importance_col], color='steelblue')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Variable\")\n",
    "    plt.title(f\"Top {top_n} variables les plus importantes\")\n",
    "    plt.gca().invert_yaxis()  # Afficher les plus importantes en haut\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des variables les plus importantes\n",
    "plot_top_n_variables(\n",
    "    importance_df = importance_df_with_labels,\n",
    "    variable_col='LIB_VAR',\n",
    "    importance_col='Importance',\n",
    "    top_n=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
