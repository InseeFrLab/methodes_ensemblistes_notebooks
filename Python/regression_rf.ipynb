{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Premier exemple de régression: prédire l'âge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le répertoire courant\n",
    "os.chdir('/home/onyxia/work/methodes_ensemblistes_notebooks')\n",
    "\n",
    "# Vérification\n",
    "print(\"Nouveau répertoire courant :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour lire les fichiers Parquet\n",
    "def read_parquet_data(local_path, var_name):\n",
    "    \"\"\"\n",
    "    Charge un fichier Parquet uniquement si la variable correspondante n'est pas déjà en mémoire.\n",
    "    \n",
    "    Args:\n",
    "        local_path (str): Chemin du fichier Parquet.\n",
    "        var_name (str): Nom de la variable à vérifier dans l'espace de noms global.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Données chargées depuis le fichier Parquet.\n",
    "    \"\"\"\n",
    "    if var_name in globals():\n",
    "        print(f\"Les données '{var_name}' sont déjà en mémoire.\")\n",
    "        return globals()[var_name]\n",
    "    \n",
    "    if os.path.exists(local_path):\n",
    "        try:\n",
    "            data = pq.read_table(local_path).to_pandas()\n",
    "            print(f\"Données Parquet chargées avec succès depuis : {local_path}\")\n",
    "            globals()[var_name] = data  # Stocker la variable dans l'espace global\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la lecture du fichier Parquet : {e}\")\n",
    "    else:\n",
    "        print(f\"Le fichier n'existe pas : {local_path}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# Fonction pour lire les fichiers CSV\n",
    "def read_csv_data(local_path, var_name):\n",
    "    \"\"\"\n",
    "    Charge un fichier CSV uniquement si la variable correspondante n'est pas déjà en mémoire.\n",
    "    \n",
    "    Args:\n",
    "        local_path (str): Chemin du fichier CSV.\n",
    "        var_name (str): Nom de la variable à vérifier dans l'espace de noms global.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Données chargées depuis le fichier CSV.\n",
    "    \"\"\"\n",
    "    if var_name in globals():\n",
    "        print(f\"Les données '{var_name}' sont déjà en mémoire.\")\n",
    "        return globals()[var_name]\n",
    "    \n",
    "    if os.path.exists(local_path):\n",
    "        try:\n",
    "            data = pd.read_csv(local_path, sep=';')\n",
    "            print(f\"Données CSV chargées avec succès depuis : {local_path}\")\n",
    "            globals()[var_name] = data  # Stocker la variable dans l'espace global\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la lecture du fichier CSV : {e}\")\n",
    "    else:\n",
    "        print(f\"Le fichier n'existe pas : {local_path}\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données si elles ne sont pas déjà en mémoire\n",
    "data_census_individuals = read_parquet_data(\"data/data_census_individuals.parquet\", \"data_census_individuals\")\n",
    "\n",
    "# Charger la documentation\n",
    "doc_census_individuals = read_csv_data(\"documentation/doc_census_individuals.csv\", \"doc_census_individuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Échantillonner les données (1/200)\n",
    "data_sample = data_census_individuals.sample(frac=1/200, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les variables liées à l'âge et celles avec trop de modalités\n",
    "columns_to_remove = ['AGER20', 'AGEREV', 'AGEREVQ', 'ANAI', 'TRIRIS', 'IRIS', \n",
    "                     'DNAI', 'DEPT', 'ARM', 'CANTVILLE', 'NUMMI', 'IPONDI', 'MODV']\n",
    "data_clean = data_sample.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les features (X) et la variable cible (y)\n",
    "X = data_clean.drop(columns=['AGED'])\n",
    "y = data_clean['AGED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage \"one-hot\" des colonnes catégoriques\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Identifier les colonnes catégoriques\n",
    "categorical_cols = X.select_dtypes(include=['category']).columns\n",
    "\n",
    "# Appliquer le One-Hot Encoding sur les colonnes catégoriques\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Convertir les colonnes encodées en DataFrame avec les noms des catégories\n",
    "X_encoded = pd.DataFrame(\n",
    "    X_encoded, \n",
    "    index=X.index, \n",
    "    columns=encoder.get_feature_names_out(categorical_cols)\n",
    ")\n",
    "\n",
    "# Sélectionner les colonnes numériques\n",
    "numeric_cols = X.select_dtypes(exclude=['category'])\n",
    "\n",
    "# Concaténer les colonnes numériques et encodées uniquement si les colonnes numériques ne sont pas vides\n",
    "if not numeric_cols.empty:\n",
    "    X = pd.concat([numeric_cols, X_encoded], axis=1)\n",
    "else:\n",
    "    X = X_encoded\n",
    "\n",
    "# Vérification finale\n",
    "print(f\"Dimensions finales après encodage : X={X.shape}\")\n",
    "print(\"Aperçu de X :\")\n",
    "print(X.head())\n",
    "\n",
    "# Vérifier les dimensions après division\n",
    "print(f\"Dimensions après division : X={X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions avant et après l'encodage\n",
    "print(f\"Dimensions avant encodage : {X.shape[0]} lignes, {categorical_cols.shape[0]} colonnes catégoriques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle Random Forest\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=5,\n",
    "    random_state=123,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "print(\"⏳ Entraînement du modèle Random Forest...\")\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation : RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats : Âge réel vs Âge prédit\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5, color=\"blue\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"Âge réel\")\n",
    "plt.ylabel(\"Âge prédit\")\n",
    "plt.title(\"Âge réel vs Âge prédit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des variables (Mean Decrease in Impurity)\n",
    "importances = rf_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Variable': X.columns, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rassembler l'importance des modalités d'une même variable\n",
    "def calculate_aggregated_importance(X, feature_importances):\n",
    "    \"\"\"\n",
    "    Agrège l'importance des variables catégorielles encodées en colonnes multiples.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Les données d'entraînement (features).\n",
    "        feature_importances (array): Les importances des variables calculées par le modèle.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Importance des variables agrégées par nom de variable.\n",
    "    \"\"\"\n",
    "    # Récupérer les noms des colonnes\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Initialiser un dictionnaire pour stocker les importances agrégées\n",
    "    aggregated_importance = {}\n",
    "\n",
    "    for col in feature_names:\n",
    "        # Identifier les variables spécifiques pour regrouper correctement\n",
    "        if col.startswith('STAT_CONJ_'):\n",
    "            variable = 'STAT_CONJ'\n",
    "        elif col.startswith('STATR_'):\n",
    "            variable = 'STATR'\n",
    "        else:\n",
    "            # Utiliser le préfixe par défaut basé sur le premier segment avant \"_\"\n",
    "            variable = col.split('_')[0]\n",
    "        \n",
    "        # Additionner les importances pour chaque variable \"parent\"\n",
    "        if variable in aggregated_importance:\n",
    "            aggregated_importance[variable] += feature_importances[feature_names.get_loc(col)]\n",
    "        else:\n",
    "            aggregated_importance[variable] = feature_importances[feature_names.get_loc(col)]\n",
    "\n",
    "    # Convertir en DataFrame trié par importance\n",
    "    aggregated_df = pd.DataFrame({\n",
    "        'Variable': aggregated_importance.keys(),\n",
    "        'Importance': aggregated_importance.values()\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appeler la fonction pour regrouper les importances\n",
    "aggregated_importance_df = calculate_aggregated_importance(X, rf_model.feature_importances_)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(aggregated_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les libellés des variables depuis le dictionnaire\n",
    "doc_census_individuals_noms_variables = doc_census_individuals[['COD_VAR', 'LIB_VAR']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associer les libellés (descriptions) aux variables d'importance\n",
    "importance_df_with_labels = aggregated_importance_df.merge(\n",
    "    doc_census_individuals_noms_variables,\n",
    "    left_on='Variable',\n",
    "    right_on='COD_VAR',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour visualiser des n variables les plus importantes\n",
    "def plot_top_n_variables(importance_df, variable_col='Variable', importance_col='Importance', top_n=10):\n",
    "    \"\"\"\n",
    "    Visualise les n variables les plus importantes à partir d'un DataFrame d'importance.\n",
    "\n",
    "    Parameters:\n",
    "    - importance_df (pd.DataFrame): Un DataFrame contenant les colonnes spécifiées.\n",
    "    - variable_col (str): Le nom de la colonne contenant les noms des variables.\n",
    "    - importance_col (str): Le nom de la colonne contenant les valeurs d'importance.\n",
    "    - top_n (int): Le nombre de variables les plus importantes à afficher.\n",
    "    \"\"\"\n",
    "    # Vérifier si les colonnes existent\n",
    "    if variable_col not in importance_df.columns or importance_col not in importance_df.columns:\n",
    "        raise ValueError(f\"Les colonnes '{variable_col}' et/ou '{importance_col}' ne sont pas présentes dans le DataFrame.\")\n",
    "\n",
    "    # Trier par importance décroissante\n",
    "    top_variables = importance_df.sort_values(by=importance_col, ascending=False).head(top_n)\n",
    "\n",
    "    # Création du graphique\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(top_variables[variable_col], top_variables[importance_col], color='steelblue')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Variable\")\n",
    "    plt.title(f\"Top {top_n} variables les plus importantes\")\n",
    "    plt.gca().invert_yaxis()  # Afficher les plus importantes en haut\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des variables les plus importantes\n",
    "plot_top_n_variables(\n",
    "    importance_df = importance_df_with_labels,\n",
    "    variable_col='LIB_VAR',\n",
    "    importance_col='Importance',\n",
    "    top_n=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée (10-fold)\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "cv_rmse = np.sqrt(-cv_scores).mean()\n",
    "print(f\"RMSE moyenne (validation croisée) : {cv_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des variables basée sur la permutation\n",
    "perm_importance = permutation_importance(rf_model, X_test, y_test, n_repeats=10, random_state=123, n_jobs=-1)\n",
    "perm_importance_df = pd.DataFrame({\n",
    "    'Variable': X.columns,\n",
    "    'Importance': perm_importance.importances_mean\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des variables les plus importantes (permutation)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(perm_importance_df['Variable'], perm_importance_df['Importance'], color='steelblue')\n",
    "plt.xlabel(\"Importance (Permutation)\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.title(\"Importance des variables (Permutation)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les variables les plus importantes\n",
    "print(perm_importance_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
